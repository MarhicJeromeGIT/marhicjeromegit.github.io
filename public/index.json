[{"content":"So I got this idea of making a Rubik\u0026rsquo;s Cube solver in Ruby and I would call it RubyCube. Hilarious, right? But kind of stupid, because nobody really cares what the solver is written in as long as it actually works. Looking back, I think similarly few users would care whether I vibe-coded it with AI or handcrafted each line, especially given that I\u0026rsquo;m not open-sourcing it. Here, for what matters, I vibe-coded the front entirely (I just told Copilot to use three.js, don\u0026rsquo;t ask me more) and manually coded the backend solver in Ruby.\nIt\u0026rsquo;s live at rubycube.jmarhic.com!\nMy 2x2x2 Rubik's cube solver\nSo, while I can\u0026rsquo;t talk much about the frontend, the backend is quite elegant. I followed part of Can a Rubik\u0026rsquo;s Cube be brute-forced—in short, I use a \u0026ldquo;brute-force + meet-in-the-middle\u0026rdquo; approach. To solve a given \u0026ldquo;state,\u0026rdquo; we compute the follow-up states by applying every possible rotation. We get a tree that we traverse in \u0026ldquo;breadth-first order\u0026rdquo; (not depth-first) to ensure we get the shortest solution. And to speed things up, I precomputed the first 6 levels (every possible state up to 6 rotations) and stored them in a db, so when solving a cube we only have to solve it \u0026ldquo;up to one of the stored states,\u0026rdquo; not \u0026ldquo;up to the initial state.\u0026rdquo; Anyway, I think reading the \u0026ldquo;solve\u0026rdquo; method below is easier to understand: notice the commented \u0026ldquo;if state == solved_state\u0026rdquo;, replaced by a db lookup \u0026ldquo;find_moves_for_state\u0026rdquo;.\nThe cube state is represented as an array of numbers (each sticker from 0 to 23—it\u0026rsquo;s a 2x2x2 cube, by the way), and a move is just a permutation of this array. It was easy to write the permutation by hand, since I had a cube at hand and just wrote the number on each sticker. The most painful part of the code was converting from a \u0026ldquo;color state\u0026rdquo; (what the frontend sends, the color of each cubie for each face) to this \u0026ldquo;permutation state\u0026rdquo; (list of numbers).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def self.solve(state) queue = [[state, []]] while !queue.empty? state, moves = queue.shift #if state == solved_state pregenerated_moves = find_moves_for_state(state) if !pregenerated_moves.nil? # Return move names instead of permutations return moves + reverse_moves(pregenerated_moves.split(\u0026#39;,\u0026#39;).reverse) end next if moves.length \u0026gt; 6 MOVES.each do |move_name, move| prev_move = moves.last # Avoid immediate inverse moves next if prev_move \u0026amp;\u0026amp; inverse_move?(prev_move,move_name) queue \u0026lt;\u0026lt; [rotate(state, move), moves + [move_name]] end end return [] # Couldn\u0026#39;t find a solution, shouldn\u0026#39;t happen end Notice I can stop the search after 6 moves—that\u0026rsquo;s because any state can be solved in less than 11 moves (it\u0026rsquo;s called God\u0026rsquo;s number), and the first 6 moves are already stored in the db. I really appreciate this \u0026ldquo;meet-in-the-middle\u0026rdquo; search where we trade some storage cost (precomputing the states and storing them in a db) for a speed boost at search time. It\u0026rsquo;s kind of like the famous \u0026ldquo;Leetcode 4 sum\u0026rdquo; problem where you have to find 4 numbers that sum up to some target; you \u0026ldquo;meet in the middle\u0026rdquo; by generating two lists instead of brute-forcing all combinations of 4 numbers.\nAnyway, that marks my first project of 2026 and I\u0026rsquo;m happy with it!\n","permalink":"https://blog.jmarhic.com/post/2026-02-14-rubycube/","summary":"\u003cp\u003eSo I got this idea of making a Rubik\u0026rsquo;s Cube solver in Ruby and I would call it RubyCube. Hilarious, right? But kind of stupid, because nobody really cares what the solver is written in as long as it actually works. Looking back, I think similarly few users would care whether I vibe-coded it with AI or handcrafted each line, especially given that I\u0026rsquo;m not open-sourcing it. Here, for what matters, I vibe-coded the front entirely (I just told Copilot to use \u003ca href=\"https://threejs.org/\"\u003ethree.js\u003c/a\u003e, don\u0026rsquo;t ask me more) and manually coded the backend solver in Ruby.\u003c/p\u003e","title":"February 2026 - Rubycube"},{"content":"Almost the end of January and no blog post yet !\nTime to remedy that. One reason for the silence is I don\u0026rsquo;t have much going on, in the past 6 months or so Claude Code and other coding agents have made such progress that pretty much anyone at my company (former QA, designers etc) is able to contribute new features to our product. It was foreseable and gradual for the past 2 years so it\u0026rsquo;s not a huge shock, though it came faster than I expected, and last year (2025) caused a big questioning about my career as a software engineer. What value can I add when anyone with minimal experience can contribute to the codebase ? The situation is not so dire yet, I do have some answers at the present (like I\u0026rsquo;m good at debugging, experience with the whole stack, etc) but nothing that feels particularly future proof. Take debugging, it takes 30 seconds of searching to find a \u0026ldquo;vscode debugger mcp\u0026rdquo; that lets agent use VSCode integrated debugging (not that I would trust it enough to install it, but we\u0026rsquo;re bound to have an official one someday). We\u0026rsquo;re already at the point where a multiple agent setup can create an app, launch it, interact with it in a browser, and debug the backend, without human assistance. Am I a better debugger than a swarm of Claude-5.2-banana agents running in the background ? I don\u0026rsquo;t believe so.\nThere is still that mysterious (to me) issue that agents can\u0026rsquo;t use interactive terminal yet (like my Gopilotty PoC), but I\u0026rsquo;m sure they\u0026rsquo;ll get to it (I found a feature request for Claude here https://github.com/anthropics/claude-code/issues/9881 , and Gemini CLI implementation only let the human, not the AI, use the PTY).\nAnd it\u0026rsquo;s not only about justifying a software engineer salary, even for personal projects it\u0026rsquo;s hard to come up with ideas that can\u0026rsquo;t be trivially done by AI yet (I want to believe my project from last year, Prosettr.com, is still AI proof though ! maybe I should just revive it). Not saying AI can one shot big projects, but I\u0026rsquo;m talking about \u0026ldquo;one weekend-er\u0026rdquo; kind of projects. I used to have some idea, work on it on friday night and saturday night, maybe see it through sunday. Now it\u0026rsquo;s done in 30 minutes and it\u0026rsquo;s not even Friday evening, what do we do next ?\nOn a related note, VS Code finally added support for Agent skills (originally introduced in Claude Code around October last year I believe), just simple markdown files with \u0026ldquo;recipes\u0026rdquo; for the model on how to do specific tasks. It feels like it will only serve to reduce the gap between experienced engineers and agent users, once I\u0026rsquo;ve skill.md\u0026rsquo;ed all my \u0026ldquo;internal knowledge\u0026rdquo; about the product I\u0026rsquo;ll really have nothing more to add, I guess it will be time to move on.\nNot that it\u0026rsquo;s a bad thing mind you ! I\u0026rsquo;ve always be doubtful of this \u0026ldquo;eternal sprint\u0026rdquo; product organization, our product is more than 10 years old, it was working fine before I joined the company, and it feels harder and harder to justify a whole division continuously working on it.\nBy the way, when I try to commit recently I\u0026rsquo;m welcomed by this new error, apparently some devs added a hook to perform a \u0026ldquo;commit lint\u0026rdquo; to make sure we respect the \u0026ldquo;conventional commit\u0026rdquo; format\u0026hellip; I won\u0026rsquo;t comment on the pedanticity of the matter (I could write a whole post about the loss of the last place of creativity in coding, but we want to autogenerate changelogs), however I noticed that to run the hook, I add to install\u0026hellip; 89 fucking packages ? For a linter that can be implemented in a regex or a small parser ? Bonus point for the potential security vulnerability added to my dev env (I use dev container so i\u0026rsquo;m not too worried about my machine, but it\u0026rsquo;s my employers API keys\u0026hellip;)\nnpm install -D @commitlint/cli @commitlint/config-conventional added 89 packages, and audited 140 packages in 6s 23 packages are looking for funding run `npm fund` for details 1 moderate severity vulnerability Which brings me back to the first point, I think one way the whole \u0026ldquo;everyone can code\u0026rdquo; thing might play out is a \u0026ldquo;let\u0026rsquo;s do everything in house\u0026rdquo; policy for more and more company. I mean that instead of importing external opensource and untrusted gems/packages, you\u0026rsquo;d just AI generate them yourself, possibly as an external library, but still controlled by you instead of some random github user. I would like that personally, in the past few years I\u0026rsquo;ve been favoring Go over Ruby or Typescript notably due to the completeness of their standard library, and I just generate dependencies instead of finding them on github (like some kind of file parser, etc). Maybe it\u0026rsquo;s not doable yet for everything (PDF parsing\u0026hellip;) but I feel like we\u0026rsquo;ll get there. At the very list that stupid commit lint command would be the first one to go if I had my way.\nOh by the way I was on a business trip to Japan earlier this month, here is a nice view of Shibuya (a little farther than the usual crossing view you get from the Starbucks).\nShibuya view from Hikarie 11th floor\n","permalink":"https://blog.jmarhic.com/post/2026-01-26-january-update/","summary":"\u003cp\u003eAlmost the end of January and no blog post yet !\u003c/p\u003e\n\u003cp\u003eTime to remedy that. One reason for the silence is I don\u0026rsquo;t have much going on, in the past 6 months or so Claude Code and other coding agents have made such progress that pretty much anyone at my company (former QA, designers etc) is able to contribute new features to our product. It was foreseable and gradual for the past 2 years so it\u0026rsquo;s not a huge shock, though it came faster than I expected, and last year (2025) caused a big questioning about my career as a software engineer. What value can I add when anyone with minimal experience can contribute to the codebase ? The situation is not so dire yet, I do have some answers at the present (like I\u0026rsquo;m good at debugging, experience with the whole stack, etc) but nothing that feels particularly future proof. Take debugging, it takes 30 seconds of searching to find a \u0026ldquo;vscode debugger mcp\u0026rdquo; that lets agent use VSCode integrated debugging (not that I would trust it enough to install it, but we\u0026rsquo;re bound to have an official one someday). We\u0026rsquo;re already at the point where a multiple agent setup can create an app, launch it, interact with it in a browser, and debug the backend, without human assistance. Am I a better debugger than a swarm of Claude-5.2-banana agents running in the background ? I don\u0026rsquo;t believe so.\u003c/p\u003e","title":"January Update"},{"content":" Merry Christmas!\n2025 Retrospective What a year it has been! I got my second kid early this year and was plenty busy with child-rearing as my number one priority, but I somehow managed to put some stuff out. Let\u0026rsquo;s get through it.\nThe good Blogging 28 posts in 2025. I managed to keep the blog alive, with around two new posts per month. I enjoy the process — it\u0026rsquo;s a nice outlet for venting and also sharing my projects. It even sometimes forced me to work on something new just to have something to write about!\nPersonal projects I\u0026rsquo;ve released four projects: Prosettr.com — a crossword generation app; Goxy — a budget limiter proxy for the OpenAI API; Gopilotty — a TTY-enabled Copilot; and Podpocket — a podcast player. I actually use Podpocket daily, as it fits my needs exactly! Also, everything was written in Go — still enjoying the language a lot!\nNotably, I built Podpocket on top of PocketBase, and it was such an enjoyable development experience. I can\u0026rsquo;t wait to start a new project with it again soon.\nI\u0026rsquo;ve also worked on minor stuff in between: The Password Game agent — an agent that plays Neal.fun\u0026rsquo;s Password Game; Pillmish — training a small LLM from scratch; etc. Given the time limitations, I\u0026rsquo;m happy with this year\u0026rsquo;s output.\nTech stuff In November I switched to Omarchy as my main distro. I found Hyprland intuitive from the get-go, especially with a dual-screen setup. It\u0026rsquo;s a pleasure to switch screens and apps just with the keyboard, and it\u0026rsquo;s super fast. I\u0026rsquo;ve made good progress de-Googling: switched to DuckDuckGo; replaced Google Photos with a self-hosted Immich instance; replaced Google Drive with a daily Backblaze backup; switched from Chrome to Chromium; and mostly stopped watching YouTube.\nHobby I recently took up Chinese Chess (Xiangqi), as it seems more popular in Vietnam than Western chess. It\u0026rsquo;s interesting to learn the new pieces, especially the Cannon, and what new strategies they offer. I\u0026rsquo;ve only been playing bots so far, as I fear I wouldn\u0026rsquo;t be a fun challenge yet. I\u0026rsquo;m trying to take it seriously, though — I acquired a bunch of Xiangqi books. I even started a Twitch channel, Paostorm, where I go through some theory and stream some games live.\nFocus for 2026 There are some areas I want to improve in 2026. Mostly, I have almost no online presence except for this blog (no idea about the readership as I don\u0026rsquo;t track metrics, but I assume zero readers), which makes sharing projects a bit difficult and demotivating. For Podpocket it was okay, as I personally needed the app as a way to replace YouTube, but for Prosettr or Goxy it feels like a shame that I didn\u0026rsquo;t manage to get more users, and I quickly lost interest.\nI guess the lesson is to work on my own needs first, but still it would be nice if my work could be useful to others. So, for 2026 I want to put myself a bit more out there.\nI\u0026rsquo;m not sure how yet; I don\u0026rsquo;t find X.com or Reddit fun, but I do enjoy streaming. I might put together a YouTube channel, or even try out TikTok. I\u0026rsquo;m neutral about Discord, might give it a try.\nLike most people, I could do with less doomscrolling on the phone. I have plenty of screen-free playtime with my kids, but I should reach for my Kindle rather than my phone during downtime.\nLastly, and without going too much into detail, I feel like it\u0026rsquo;s time to move on to a new job. I\u0026rsquo;ve been working at the same company for the past six years, and it has kind of stopped being fun. My Japan visa is also almost up, so I might just not renew it and call it quits. But it means I need to find another position somehow (I\u0026rsquo;m not going to live off streaming!), which also means putting myself out on LinkedIn. Dreary.\nOn a similar note, I\u0026rsquo;ve recently been dialing back my use of coding agents in favor of a somewhat slower and more thoughtful development process. I even turned off Copilot completely and wrote some functions (a throttle function in Go) entirely by hand — like it\u0026rsquo;s 2022 again! It obviously took longer than ChatGPT, but the end result was mine and did just what I wanted and nothing more — and I understood it. I found I enjoyed the process, which means I do still like programming, luckily :)\nMerry Christmas Today I\u0026rsquo;m starting a two-week vacation! I want to find out whether being off work will trigger my creativity because I often daydream about working solo on my own projects, but I fall short on actual ideas. Looking forward to an interesting 2026!\n","permalink":"https://blog.jmarhic.com/post/2025-12-25-merry-christmas/","summary":"\u003cimg src=\"/assets/images/christmas_lego.jpg\" alt=\"A Santa made of LEGO\" height=\"500\" loading=\"lazy\" style=\"display:block;margin: 0 auto;\" /\u003e\n\u003cp style=\"text-align:center\"\u003e\u003cem\u003eMerry Christmas!\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"2025-retrospective\"\u003e2025 Retrospective\u003c/h2\u003e\n\u003cp\u003eWhat a year it has been! I got my second kid early this year and was plenty busy with child-rearing as my number one priority, but I somehow managed to put some stuff out. Let\u0026rsquo;s get through it.\u003c/p\u003e\n\u003ch2 id=\"the-good\"\u003eThe good\u003c/h2\u003e\n\u003ch3 id=\"blogging\"\u003eBlogging\u003c/h3\u003e\n\u003cp\u003e28 posts in 2025. I managed to keep the blog alive, with around two new posts per month. I enjoy the process — it\u0026rsquo;s a nice outlet for venting and also sharing my projects. It even sometimes forced me to work on something new just to have something to write about!\u003c/p\u003e","title":"Merry Christmas! 2025 Retrospective"},{"content":"I\u0026rsquo;ve been frustrated with YouTube Music as a podcast player ever since Google retired Google Podcast last year, mostly because they now play ads before each episode! So I\u0026rsquo;ve decided to develop and release a minimal podcast player, Podpocket.\nIt was really a pleasure to develop it with Pocketbase, as it handled everything I need:\nauthentication (including oauth) setup in a few clicks a UI to create new collections (sqlite tables), and a complete admin dashboard Even Cron jobs (to refresh the RSS feeds periodically) And best of all, it\u0026rsquo;s written in Go so you can extend it super easily. For instance, I added an endpoint to register new RSS feeds, and I still have a single unified backend. This is unlike Firebase where you end up with a split architecture where some calls go directly to Firebase services and others to your custom backend. I\u0026rsquo;m definitely going to reuse it in my next project. A fun feature is the user impersonation that lets an admin login as another user.\nAll said, I\u0026rsquo;m pretty happy with the result itself, especially given how quickly I made it. It\u0026rsquo;s bare-bone but I do actually use it myself! It looks decent on mobile, the feeds are refreshed regularly, the player saves the listening progress. I hosted the frontend on AWS Cloudfront, and the backend is now on Hetzner. I originally put it on Fly.io (with scaling to 0) but as I needed cron jobs I first moved it to my home Raspberry Pi behind a Tailscale Funnel but it didn\u0026rsquo;t feel resilient (I regularly power down the raspberry), so I eventually decided to put it on a Hetzner VPS.\nLet me guess, you need more ?\nAnyway, feel free to give it a try! There is a big issue with discoverability; I just mark my episodes as recommended. I could find a list of podcasts but I don\u0026rsquo;t want to recommend stuff that I don\u0026rsquo;t listen to myself. So you have to bring your own RSS links, basically :) The link is podpocket.jmarhic.com – I don\u0026rsquo;t want to pay for a custom domain for it.\n","permalink":"https://blog.jmarhic.com/post/2025-12-11-podpocket/","summary":"\u003cp\u003eI\u0026rsquo;ve been frustrated with YouTube Music as a podcast player ever since Google retired \u003ca href=\"https://killedbygoogle.com/\"\u003eGoogle Podcast\u003c/a\u003e last year, mostly because they now play ads before each episode! So I\u0026rsquo;ve decided to develop and release a minimal podcast player, \u003ca href=\"https://podpocket.jmarhic.com/\"\u003ePodpocket\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIt was really a pleasure to develop it with \u003ca href=\"https://pocketbase.io/\"\u003ePocketbase\u003c/a\u003e, as it handled everything I need:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eauthentication (including oauth) setup in a few clicks\u003c/li\u003e\n\u003cli\u003ea UI to create new collections (sqlite tables), and a complete admin dashboard\u003c/li\u003e\n\u003cli\u003eEven Cron jobs (to refresh the RSS feeds periodically)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnd best of all, it\u0026rsquo;s written in Go so you can extend it super easily. For instance, I added an endpoint to register new RSS feeds, and I still have a single unified backend. This is unlike Firebase where you end up with a split architecture where some calls go directly to Firebase services and others to your custom backend. I\u0026rsquo;m definitely going to reuse it in my next project. A fun feature is the \u003ca href=\"https://pocketbase.io/docs/authentication/#users-impersonation\"\u003euser impersonation\u003c/a\u003e that lets an admin login as another user.\u003c/p\u003e","title":"Podpocket release"},{"content":" Vietnam has been hit hard by heavy rain lately, but the skies were clear this morning. I drove my daughter to school on a scooter, and since we were early we took a longer route across the river. From the bridge we saw a giant rubber duck they installed on the other side of the river, pretty cool ! Arrived at school she asked me to stay for the morning dance, so I watched her jumping to the sound of DJ Raphi\u0026rsquo;s ABC song with 50 other kindergartners. That was an energetic morning ! Just what I needed so I could resume work on this sprint ticket.\nLast week I\u0026rsquo;ve released Gopilotty, my take on a CLI based agent that can be used with interactive (full screen) commands. Basically it can \u0026ldquo;write\u0026rdquo; into VIM, or any CLI like redis or sqlite, ruby REPL etc\u0026hellip; I think it\u0026rsquo;s pretty cool honestly, haven\u0026rsquo;t seen that from the big names yet. I made a YouTube video for it : https://www.youtube.com/watch?v=PfCqlAJxpQQ and that\u0026rsquo;s pretty much all the marketing I intend to do for it.\nMoving on, I picked up \u0026ldquo;twitch streaming\u0026rdquo; as a hobby ! I made a twitch channel, Paostorm and my plan is to be streaming Chinese Chess games whenever times allow (spoiler alert, times only allow after 10pm and I\u0026rsquo;m not at my best at this time !)\nI\u0026rsquo;ve been playing Huma, the \u0026ldquo;level 3\u0026rdquo; bot on Xiangqi.com. My impression is it plays all the best moves in the opening, then randomly commits some dramatic blunders in order to give the player a chance. It doesn\u0026rsquo;t feel very humanlike, I\u0026rsquo;d rather the bot consistently play the second or third best move — or, better, train the bot less or on lesser quality games and have it play what it believes is the best move, just like a human would. Anyway I\u0026rsquo;m still having a hard time beating it, I normally need to \u0026ldquo;undo\u0026rdquo; several moves per game due to stupid mistakes. But I\u0026rsquo;m starting to get a better feeling on whether my position is tenable or desperate.\nI hope that streaming helps me to think better by voicing my thoughts, and forces me to make progress. I\u0026rsquo;ll try to keep a good mix of \u0026ldquo;theory vs practice\u0026rdquo;, though Chinese Chess is less theory heavy than western chess, as far as I know.\n","permalink":"https://blog.jmarhic.com/post/2025-11-24-monday-morning/","summary":"\u003chr\u003e\n\u003cp\u003eVietnam has been hit hard by heavy rain lately, but the skies were clear this morning. I drove my daughter to school on a scooter, and since we were early we took a longer route across the river. From the bridge we saw a giant rubber duck they installed on the other side of the river, pretty cool ! Arrived at school she asked me to stay for the morning dance, so I watched her jumping to the sound of \u003ca href=\"https://www.youtube.com/watch?v=V6fGupFWQ7o\"\u003eDJ Raphi\u0026rsquo;s ABC song\u003c/a\u003e with 50 other kindergartners. That was an energetic morning ! Just what I needed so I could resume work on this sprint ticket.\u003c/p\u003e","title":"2025 11 24 Monday morning"},{"content":"A lot going on these days!\nI succumbed to the hype and installed Omarchy, the new Linux distro by DHH. It\u0026rsquo;s basically Arch Linux with a tiling window manager (Hyprland), but it comes pre-configured and installable with an ISO, which is super convenient compared to the usual Arch install process. So out of the box you get a very good-looking desktop with nice shortcuts and documentation.\nSome will disagree with DHH\u0026rsquo;s preferences and choices, but realistically I would never have taken the time to configure Hyprland properly myself, so it\u0026rsquo;s nice to be able to rely on somebody\u0026rsquo;s taste (I trust DHH\u0026rsquo;s taste more than mine in that regard!). Same goes for the rest of the desktop environment (waybar for the top bar, walker for the app launcher\u0026hellip;). That was my main issue with Arch, too much choice and alternatives that I don\u0026rsquo;t really care about (I just want internet, not to have to choose a network manager\u0026hellip;). So I really see the appeal of Omarchy for many people, and it seems to be gaining popularity.\nI think it can be a nice gateway to more advanced Linux usage. I\u0026rsquo;ve already made a few basic changes (added a couple of web apps to the launcher and reduced the gap between windows as my screen is quite small). It\u0026rsquo;s pretty easy to configure. And the themes are very pretty!\nMoving on, I\u0026rsquo;ve been making little progress on Goxy, my budget limiter for OpenAI API - mostly rewrote the \u0026ldquo;money\u0026rdquo; handling to use integers instead of floats :) I just want to handle \u0026ldquo;streaming\u0026rdquo; completions and I\u0026rsquo;ll release it.\nI also started a new project that I\u0026rsquo;m quite excited about - not quite ready to release the code but I have a demo. I call it \u0026ldquo;gopilotty\u0026rdquo; (it\u0026rsquo;s a Go copilot in the tty). The twist is that it works in \u0026ldquo;interactive\u0026rdquo; terminal mode (think vim, sqlite3, or a Ruby REPL), not just for \u0026ldquo;one-off\u0026rdquo; bash commands.\nYour browser does not support the video tag. Basically, it opens a two-pane window: the left pane is a bash terminal and the right pane a chatbot, but the chatbot is able to execute commands in the left pane - without hanging, even for interactive commands like vim. So you can have the agent write some document in vim, navigate a database, and execute some Ruby script line by line. Still a bit buggy as you can see in the video, but I think it\u0026rsquo;s cool nevertheless :)\nIt\u0026rsquo;s a combination of creak/pty to create a pseudo terminal, hinshun/vt10x for the terminal emulation (so that special keys like backspace etc. are handled properly), and gdamore/tcell (and rivo/tview) for the terminal UI.\nAlright, lastly, I\u0026rsquo;ve been trying to learn Chinese Chess (Xiangqi).\nIt\u0026rsquo;s\u0026hellip; quite a big departure from \u0026ldquo;western\u0026rdquo; chess with a slightly bigger board, different pieces (the elephant, which moves like a bishop but is limited in range and can\u0026rsquo;t cross the board; the cannon is confusing as well as it needs a \u0026ldquo;screen,\u0026rdquo; a piece in between it and its target in order to be able to capture), and especially the knight that cannot jump. So it\u0026rsquo;s a bit of a mental gymnastic to \u0026ldquo;unlearn\u0026rdquo; western chess - which I was never really good at - and figure out how to use those new pieces efficiently. I\u0026rsquo;ve been doing some puzzles and playing against the computer. Xiangqi is quite popular in Vietnam and many grandpas are playing daily in the square nearby. I look forward to playing with them (I\u0026rsquo;ve played once but got defeated immediately -_-).\n","permalink":"https://blog.jmarhic.com/post/2025-11-05-november-update/","summary":"\u003cp\u003eA lot going on these days!\u003c/p\u003e\n\u003cp\u003eI succumbed to the hype and installed \u003ca href=\"https://omarchy.org/\"\u003eOmarchy\u003c/a\u003e, the new Linux distro by DHH. It\u0026rsquo;s basically Arch Linux with a tiling window manager (\u003ca href=\"https://hypr.land/\"\u003eHyprland\u003c/a\u003e), but it comes pre-configured and installable with an ISO, which is super convenient compared to the usual Arch install process. So out of the box you get a very good-looking desktop with nice shortcuts and documentation.\u003c/p\u003e\n\u003cp\u003eSome will disagree with DHH\u0026rsquo;s preferences and choices, but realistically I would never have taken the time to configure Hyprland properly myself, so it\u0026rsquo;s nice to be able to rely on somebody\u0026rsquo;s taste (I trust DHH\u0026rsquo;s taste more than mine in that regard!). Same goes for the rest of the desktop environment (waybar for the top bar, walker for the app launcher\u0026hellip;). That was my main issue with Arch, too much choice and alternatives that I don\u0026rsquo;t really care about (I just want internet, not to have to choose a network manager\u0026hellip;). So I really see the appeal of Omarchy for many people, and it seems to be gaining popularity.\u003c/p\u003e","title":"2025 11 05 November Update"},{"content":"Sadly, this week saw the passing of Chess Grandmaster and streamer Daniel Narodistky and it came as a shock for a lot of people including me. I was particularly a fan of his \u0026ldquo;speedrun\u0026rdquo; videos, it really helped demystify chess. I used to think high level chess was this impenetrable mix of \u0026ldquo;opening\u0026rdquo; knowledge and thinking 20 moves in advance, but he really showed how each move made sense in an almost obvious way, either positionally or tactically. Watching his videos you get the feeling that you grasp chess and that, of course you could have won that game too, that was easy ! (only to lose against a 1000 ELO in your next game).\nGuy seemed like a class act in real life as well, and it is a great loss for chess and the world in general. It was really unexpected, having released a video just a few days prior. One of the only Youtuber I subscribe too for his personality rather than the subject itself (the others would be ThreeBlueOneBrown and Andrej Karpathy), often watching his videos just before sleeping as it was such a relaxing watch.\nI guess that\u0026rsquo;s all I feel like saying for today !\n","permalink":"https://blog.jmarhic.com/post/2025-10-24-rip-daniel-narodistky/","summary":"\u003cp\u003eSadly, this week saw the passing of Chess Grandmaster and streamer \u003ca href=\"https://www.youtube.com/@DanielNaroditskyGM\"\u003eDaniel Narodistky\u003c/a\u003e and it came as a shock for a lot of people including me. I was particularly a fan of his \u0026ldquo;speedrun\u0026rdquo; videos, it really helped demystify chess. I used to think high level chess was this impenetrable mix of \u0026ldquo;opening\u0026rdquo; knowledge and thinking 20 moves in advance, but he really showed how each move made sense in an almost obvious way, either positionally or tactically. Watching his videos you get the feeling that you grasp chess and that, of course you could have won that game too, that was easy ! (only to lose against a 1000 ELO in your next game).\u003c/p\u003e","title":"Rip Daniel Narodistky"},{"content":" A programmer says \u0026ldquo;I have 2 kids, and the sum of their age is 4\u0026rdquo;.\nThe logician thinks and says \u0026ldquo;not enough info\u0026rdquo;.\nThe programmer adds \u0026ldquo;The eldest likes Bluey\u0026rdquo;.\nThe logician smiles and replies \u0026ldquo;Ah ! You must be using vibe coding a lot\u0026rdquo;.\nAlright, I\u0026rsquo;ve been working on a new project, Goxy: an OpenAI proxy that track \u0026amp; limit spending. You can set an hourly limit (say 1$ per hour) and the proxy will return 429 errors when the spend reaches the limit. That lets you release LLM using projects while being confident you won\u0026rsquo;t get hit with a thousand-dollar bill at the end of the month.\nIt\u0026rsquo;s written in Go and mostly vibe-coded (from VSCode copilot), though I\u0026rsquo;m controlling the flow and trying to make piece-wise PRs. Execution notwithstanding, I think the idea is sound, I\u0026rsquo;m not aware of a way to set a hard budget limit to a given OpenAI API key, they\u0026rsquo;ll just email you when you reach a preset budget but nothing prevents you to go over it. I\u0026rsquo;m kind of excited about it because I shared it in the latest HackerNews \u0026ldquo;What are you working on\u0026rdquo; thread and got 2 stars on it !\nNot much else going on, I\u0026rsquo;ve just came back from Tokyo so here\u0026rsquo;s a picture of Shibuya station ongoing construction.\n","permalink":"https://blog.jmarhic.com/post/2025-10-15-october-update/","summary":"\u003cblockquote\u003e\n\u003cp\u003eA programmer says \u0026ldquo;I have 2 kids, and the sum of their age is 4\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eThe logician thinks and says \u0026ldquo;not enough info\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eThe programmer adds \u0026ldquo;The eldest likes Bluey\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eThe logician smiles and replies \u0026ldquo;Ah ! You must be using vibe coding a lot\u0026rdquo;.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eAlright, I\u0026rsquo;ve been working on a new project, \u003ca href=\"https://github.com/goverture/goxy\"\u003eGoxy\u003c/a\u003e: an OpenAI proxy that track \u0026amp; limit spending. You can set an hourly limit (say 1$ per hour) and the proxy will return 429 errors when the spend reaches the limit. That lets you release LLM using projects while being confident you won\u0026rsquo;t get hit with a thousand-dollar bill at the end of the month.\u003c/p\u003e","title":"Logic riddle (October update)"},{"content":"I just came back from a two weeks vacation in France with my daughter, and without my laptop, which was pretty nice. As a result I don\u0026rsquo;t have much to say for this month !\nAfter coming back I had an idea for a small project, a \u0026ldquo;guess who\u0026rdquo; app that I vibecoded in a few hours with Firebase Studio. It got me a Next.js+tailwindcss app pretty quickly, with LLM calls handled by Genkit. Originally it was using the Gemini API and hosted on Firebase, but I\u0026rsquo;ve changed it to GPT-5 and Fly.io for hosting.\nI haven\u0026rsquo;t looked much at the code actually, but the LLM part of it seems clean and use Genkit flows, and the app works well enough that I call it a success ! I\u0026rsquo;m not quite ready to release (mostly I need to put some kind of spending limit on the API token). It\u0026rsquo;s so strange that the main LLM providers don\u0026rsquo;t allow setting a maximum spending limit on a given API token already. I\u0026rsquo;m not going to risk spending thousands on a stupid app in case it might go viral !\nOh, and I migrated my blog from Jekyll to Hugo. No special reason for the change, these days I\u0026rsquo;m much more into Go than Ruby, and it was pretty painless with the Import command. I still have to fix some links.\nTo finish with, a cool picture of my home viewed from the plane, on the way back !\n","permalink":"https://blog.jmarhic.com/post/2025-09-25-september-update/","summary":"\u003cp\u003eI just came back from a two weeks vacation in France with my daughter, and without my laptop, which was pretty nice. As a result I don\u0026rsquo;t have much to say for this month !\u003c/p\u003e\n\u003cp\u003eAfter coming back I had an idea for a small project, a \u0026ldquo;guess who\u0026rdquo; app that I vibecoded in a few hours with \u003ca href=\"https://firebase.studio/\"\u003eFirebase Studio\u003c/a\u003e. It got me a Next.js+tailwindcss app pretty quickly, with LLM calls handled by \u003ca href=\"https://genkit.dev/\"\u003eGenkit\u003c/a\u003e. Originally it was using the Gemini API and hosted on Firebase, but I\u0026rsquo;ve changed it to GPT-5 and Fly.io for hosting.\u003c/p\u003e","title":"September Update"},{"content":"So in my [last post about Pilish]({% post_url 2025-08-09-pillmish %}) I mentioned that a follow up to get better results would be to use a LLM with word level tokenization. It\u0026rsquo;s actually a bad idea in general because the vocabulary size can be huge, and that\u0026rsquo;s why most LLM these days use BPE or subword tokenization, but I decided to give it a quick try and train a LLM from scratch with word level tokenization. Back in 2023 I used to be quite into finetuning and all that but this year I haven\u0026rsquo;t done much low level tinkering with LLM so it was a good exercise.\nHuggingface has done a great job with their Trainer method so it\u0026rsquo;s actually very straightforward:\ncreate a tokenizer (here, word level) define a model (I just reused the GPT-2 model and played a bit with the parameters to get something quick to train) train the model inference I put the scripts in this repo : Pillmish\nFor the dataset, I used Tinystories. It was an experiment on getting comparatively very small LLM to write coherent english text, see the paper How Small Can Language Models Be and Still Speak Coherent English?. Using this dataset, I knew that my small model (around 5M parameters) should also be able to generate coherent text. Also it uses a simplified vocabulary, which is important to keep my word level tokenizer small. In total I limited to the default, 30k vocabulary size.\nLong story short, after training for around 45 minute the loss was good (I forgot but around 3 something) and the sentences look reasonable. Here are a few generation (prompt in bold):\nonce upon a time , there was a little boy named timmy . timmy loved to play outside with his friends . one day , timmy \u0026rsquo; s mom asked him to build a big snowman . timmy was so excited to help his mom and dad . after a while , timmy \u0026rsquo; s dad said , \u0026quot; timmy , we are going to clean the castle ! see how heavy the snowman can put in a big castle .\u0026quot; timmy watched as his mom combed his head . he was so happy ! after that day , timmy \u0026rsquo; s dad decided the king and the queen had a silly day . the king was very rich . the king had a big farm with many animals . he was a lot of animals and animals . one day , a little girl came to the castle . she had a big , red car . she had a big bow on the wall . the little girl said , \u0026quot; hello , queen . i am a king .\u0026quot; the king looked at the little girl . he said , \u0026quot; can i borrow it ?\u0026quot; the little girl was sad . she thought for a tom saw a cat in the yard . he wanted to pet it . he saw a big truck with sharp claws . tom wanted to pet the truck , so he took the truck . but the truck was too big and heavy . tom took the truck and ran away . the truck opened the door and saw a little girl . the man had big eyes . the truck opened its door , and the man opened the truck . the truck was very big . he could not see that the truck was broken . he wanted the truck to Alright, to get back to the Pilish problem, if I apply the LogitProcessor to constrain the generation to word matching the Pi digits, we get\u0026hellip;\nleo a very a brave alligator in school every day after drinking something special somewhere new in the sunshine that looked so loudly that all the children had to discuss listening about everything he belonged belonged from a beautiful village a nearby crocodile who continued searching for answers right a mysterious voice whenever he discovered something strange that disturbed them\n(digits of Pi for reference: 3.1415926535). I think it\u0026rsquo;s acceptable given the size of the model (5M params trained for 45 minutes on a single RTX 3060). Mostly it was a proof of concept, but it got me interested in training again ! It\u0026rsquo;s impressive what small models can achieve when given a good dataset.\n","permalink":"https://blog.jmarhic.com/post/2025-08-16-training-a-small-llm/","summary":"\u003cp\u003eSo in my [last post about Pilish]({% post_url 2025-08-09-pillmish %}) I mentioned that a follow up to get better results would be to use a LLM with word level tokenization. It\u0026rsquo;s actually a bad idea in general because the vocabulary size can be huge, and that\u0026rsquo;s why most LLM these days use BPE or subword tokenization, but I decided to give it a quick try and train a LLM from scratch with word level tokenization. Back in 2023 I used to be quite into finetuning and all that but this year I haven\u0026rsquo;t done much low level tinkering with LLM so it was a good exercise.\u003c/p\u003e","title":"Training a small LLM"},{"content":"A few days ago, I heard about Pilish for the first time. As Wikipedia puts it, Pilish is a style of constrained writing in which the lengths of consecutive words or sentences match the digits of the number π (pi). My second thought (right after \u0026ldquo;who would enjoy doing that\u0026rdquo;) was, this sounds easy for LLMs! So I set out to make a minimal proof of concept.\nLong story short, the trick is to constrain the output to follow the digits of Pi—the same way that structured output (JSON, etc.) works. With Hugging Face Transformers, it\u0026rsquo;s easy to do with a custom logits_processor. Here, we just constrain the tokens to those matching the desired number of characters at each step. I shared the code on GitHub.\nHere are a few samples I generated:\nand I have a small apartment in London which has three bedrooms including private bathrooms and my own bathroom with you d have a whole community of people where you could interact virtually without requiring you to get involved with isn t even a place dedicated to making money and doing anything important besides promoting you to the audience that You can see the letter count is 3,14159\u0026hellip;\nSo that\u0026rsquo;s that. Now, the model I used, facebook/opt-125m, is rather small and the tokenizer uses Byte Pair Encoding (BPE)—meaning a lot of words are split into multiple tokens, so the results are obviously subpar. But you get the idea. That\u0026rsquo;s about as far as I\u0026rsquo;m willing to go, as I already lost interest in the whole affair. Some possible next steps would be to stop the generation or backtrack depending on the loss, and maybe train a model from scratch using a word-level encoding. Also, you could easily implement a trick where two digits like \u0026ldquo;11\u0026rdquo; could be interpreted as an eleven-letter word as well as two one-letter words, etc.\n","permalink":"https://blog.jmarhic.com/post/2025-08-09-pillmish/","summary":"\u003cp\u003eA few days ago, I heard about \u003ca href=\"https://en.wikipedia.org/wiki/Pilish\"\u003ePilish\u003c/a\u003e for the first time. As Wikipedia puts it, \u003ccode\u003ePilish is a style of constrained writing in which the lengths of consecutive words or sentences match the digits of the number π (pi).\u003c/code\u003e My second thought (right after \u0026ldquo;who would enjoy doing that\u0026rdquo;) was, this sounds easy for LLMs! So I set out to make a minimal proof of concept.\u003c/p\u003e\n\u003cp\u003eLong story short, the trick is to constrain the output to follow the digits of Pi—the same way that structured output (JSON, etc.) works. With Hugging Face Transformers, it\u0026rsquo;s easy to do with a custom \u003ccode\u003elogits_processor\u003c/code\u003e. Here, we just constrain the tokens to those matching the desired number of characters at each step. I shared the code on \u003ca href=\"https://gist.github.com/MarhicJeromeGIT/d01f79363420c8c10d5aeba10c4c9960\"\u003eGitHub\u003c/a\u003e.\u003c/p\u003e","title":"Pillmish"},{"content":"Lot of things going on this summer, but yesterday\u0026rsquo;s big news was the release of ChatGPT 5. I don\u0026rsquo;t have an opinion on it yet, but I guess it\u0026rsquo;s nice to have a single model (at least exposed, even if this is routed under the hood) instead of switching between 4o and o4-mini-high, etc.\nRecently I\u0026rsquo;ve been on the market for a \u0026ldquo;CLI Agent\u0026rdquo; (synchronous, like Claude Code, not async like Devin and co.). I\u0026rsquo;ve been using Gemini CLI with good results — as long as I\u0026rsquo;m within the free PRO requests. As soon as it switches to the \u0026ldquo;flash\u0026rdquo; model it becomes useless, can\u0026rsquo;t edit a file properly, and just loops on itself. I wouldn\u0026rsquo;t pay for it. Claude Code seems too expensive; I might give OpenAI Codex a try with GPT-5, but I haven\u0026rsquo;t heard much about it.\nI\u0026rsquo;ve been vibe coding a \u0026ldquo;sun earth moon\u0026rdquo; system with day and night cycles. Nothing fancy, it\u0026rsquo;s to teach my 3-year-old about space, time zones, and moon cycles, and it\u0026rsquo;s fun to make something graphical. Eventually I want to get the moon cycles right (ideally in sync with the real time on Earth).\nLet\u0026rsquo;s see, what else? Also on Google\u0026rsquo;s side, I noticed I had access to the video diffusion model Veo 3 in the Gemini app! It\u0026rsquo;s pretty good — you can prompt from scratch and also provide a starting image for the video. I got this video of Jensen plugging a GPU in a rack. The stop-motion is a nice touch for a Lego animation.\nYour browser does not support the video tag. Lastly, I wanted to speak about Open Source. This week there was a popular post on Hacker News that I found pretty tasteless, I gave the AI arms and legs then it rejected me. The short story is that the author found out that Anthropic uses his open source library as part of Claude Code and he somehow thought that ought to give him a chance for a job interview, and when that didn\u0026rsquo;t happen (likely an automated rejection) he went to blog and post about it (a second time in Ask HN: Have you ever regretted open-sourcing something?).\nMy take is that if the library was that valuable and complex, maybe don\u0026rsquo;t give it away for free in the first place? I\u0026rsquo;ve considered for a long time now that Open Source is devaluing software engineers by taking away the \u0026ldquo;fun parts\u0026rdquo; (technically interesting) and just leaving the dregs of plugging stuff together. As a software engineer working on a new feature, you\u0026rsquo;re usually expected to find a suitable existing library rather than code your own, so you end up with a very shallow knowledge of the subject. Don\u0026rsquo;t get me wrong, I\u0026rsquo;m glad for Redis, Nginx, Linux, and countless other software etc. being open source! But notice that they are backed by companies or sponsors; it\u0026rsquo;s not about an individual or two toiling away and complaining about not being funded. The reason for using an open source library is that it\u0026rsquo;s free — you can\u0026rsquo;t expect to profit from it. See what happens when popular projects like Redis actually tried to change their license — they got forked immediately.\nAnyway, I tend to favor languages that come with a comprehensive standard library — see how in Go you usually make web apps without needing a framework — and reduce the number of vendored dependencies along with the security risk. And I don\u0026rsquo;t see any reason to make my own projects open source (save for one-off scripts etc. that can be useful to some and wouldn\u0026rsquo;t make money anyway).\n","permalink":"https://blog.jmarhic.com/post/2025-08-08-august-2025-update/","summary":"\u003cp\u003eLot of things going on this summer, but yesterday\u0026rsquo;s big news was the release of ChatGPT 5. I don\u0026rsquo;t have an opinion on it yet, but I guess it\u0026rsquo;s nice to have a single model (at least exposed, even if this is routed under the hood) instead of switching between 4o and o4-mini-high, etc.\u003c/p\u003e\n\u003cp\u003eRecently I\u0026rsquo;ve been on the market for a \u0026ldquo;CLI Agent\u0026rdquo; (synchronous, like Claude Code, not async like Devin and co.). I\u0026rsquo;ve been using \u003ca href=\"https://github.com/google-gemini/gemini-cli\"\u003eGemini CLI\u003c/a\u003e with good results — as long as I\u0026rsquo;m within the free PRO requests. As soon as it switches to the \u0026ldquo;flash\u0026rdquo; model it becomes useless, can\u0026rsquo;t edit a file properly, and just loops on itself. I wouldn\u0026rsquo;t pay for it. Claude Code seems too expensive; I might give \u003ca href=\"https://github.com/openai/codex\"\u003eOpenAI Codex\u003c/a\u003e a try with GPT-5, but I haven\u0026rsquo;t heard much about it.\u003c/p\u003e","title":"August 2025 Update (GPT-5, Veo 3, Gemini CLI, Open Source)"},{"content":"So I started reading a paper about diffusion (the original DDPM paper) and I was quickly out of my depth. I needed a refresher about probabilities, and actually even more basic stuff like exponential and integration. And I thought why not share the notes here! So this blog post is the content of a python notebook about exponential and the normal distribution, exported to markdown with jupyter nbconvert. It\u0026rsquo;s not deep or anything, just a nice refresher for myself. Kind of a pain to write math formulas and get them displayed in my Jekyll blog but got it working with Mathjax.\n1 2 import matplotlib.pyplot as plt import numpy as np Let\u0026rsquo;s get started with the exponential: $exp(x) = e^x$.\nIt\u0026rsquo;s a function that tends to 0 for $-\\infty$ and goes up very quickly as x grows.\nThere are a few things to know about it :\n$e^0 = 1$\n$e^1 = e \\approx 2.718 $\nand the slope (ie the derivative) is the exponential itself ie:\n$\\frac{d}{dx} e^x = e^x $\nLet\u0026rsquo;s graph it !\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import matplotlib.pyplot as plt import numpy as np x = np.linspace(-5, 5, 100) y = np.exp(x) plt.plot(x, y) # Values at 0 and 1 plt.scatter([0, 1], [np.exp(0), np.exp(1)], color=\u0026#39;red\u0026#39;) plt.text(0, np.exp(0), f\u0026#34;({0}, {np.exp(0):.2f})\u0026#34;, fontsize=10, ha=\u0026#39;right\u0026#39;, va=\u0026#39;bottom\u0026#39;) plt.text(1, np.exp(1), f\u0026#34;({1}, {np.exp(1):.2f})\u0026#34;, fontsize=10, ha=\u0026#39;left\u0026#39;, va=\u0026#39;bottom\u0026#39;) # Slope at 3 (draw between 2 and 4) a3 = np.exp(3) b3 = np.exp(3) x_tangent3 = np.linspace(2, 4, 50) y_tangent3 = a3 * (x_tangent3 - 3) + b3 plt.plot(x_tangent3, y_tangent3, color=\u0026#39;orange\u0026#39;, label=f\u0026#39;Tangent at x=3 (slope={a3:.2f})\u0026#39;) plt.text(3, a3*0.2 + b3, f\u0026#34;Slope at x=3: {a3:.2f}\u0026#34;, color=\u0026#39;orange\u0026#39;, fontsize=10) # Slope at 5 (draw between 4.9 and 5.1) a5 = np.exp(5) b5 = np.exp(5) x_tangent5 = np.linspace(4.9, 5.1, 50) y_tangent5 = a5 * (x_tangent5 - 5) + b5 plt.plot(x_tangent5, y_tangent5, color=\u0026#39;red\u0026#39;, label=f\u0026#39;Tangent at x=5 (slope={a5:.2f})\u0026#39;) plt.text(5, a5*0.1 + b5, f\u0026#34;Slope at x=5: {a5:.2f}\u0026#34;, color=\u0026#39;red\u0026#39;, fontsize=10) # extra design options plt.title(\u0026#34;exp(x)\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;exp(x)\u0026#34;) plt.grid(True) plt.legend() plt.show() OK now what about the negative $e^{-x}$ ? It\u0026rsquo;s the same as $1/e^x$ and it\u0026rsquo;s used as a decay.\n1 2 3 4 5 6 7 8 9 10 11 12 13 x = np.linspace(-5, 5, 100) y = np.exp(-x) plt.plot(x, y) x_reciprocal = np.linspace(-5, 5, 10) y_reciprocal = 1 / np.exp(x_reciprocal) plt.scatter(x_reciprocal, y_reciprocal, color=\u0026#39;red\u0026#39;) plt.title(\u0026#34;exp(-x)\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;exp(-x)\u0026#34;) plt.grid(True) plt.show() Now in probabilities, to make the nice bell shape we use $e^{-x^2}$. The \u0026ldquo;square\u0026rdquo; part is to make $x$ always positive (so we have the symmetry about zero or whatever mean we want, the \u0026ldquo;$\\mu$\u0026rdquo; in the Gaussian formula) and the \u0026ldquo;minus\u0026rdquo; ensures the decay.\n1 2 3 4 5 6 7 8 9 x = np.linspace(-5, 5, 100) y = np.exp(-(x ** 2)) plt.plot(x, y) plt.title(\u0026#34;exp(-x²)\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;exp(-x²)\u0026#34;) plt.grid(True) plt.show() Now, the Gaussian integral $ I = \\int_{-\\infty}^{\\infty} e^{-x^2} , dx$ can be shown to be equal to $\\sqrt \\pi$ (the trick is to compute $I^2$ and then to switch to polar coordinate etc etc).\nFrom here we can define the PDF (Probability Density Function) that will have an integral of 1 thanks to a normalization factor :\n$$\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2 / 2}$$\nSo it\u0026rsquo;s like the normal distribution $\\mathcal{N}$ with variance of 1 and mean of 0.\nThe mean is written \u0026ldquo;mu\u0026rdquo; ($\\mu$) and the standard deviation is sigma ($\\sigma$) (it measures the spread), and the variance is $\\sigma^2$. Let\u0026rsquo;s draw it for various sigmas !\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import numpy as np import matplotlib.pyplot as plt x = np.linspace(-10, 10, 500) mu = 0 sigmas = [0.5, 1, 2, 3] # Various standard deviations plt.figure(figsize=(10, 5)) for sigma in sigmas: y = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-(x - mu)**2 / (2*sigma**2)) plt.plot(x, y, label=fr\u0026#39;$\\sigma={sigma}$\u0026#39;) plt.title(\u0026#34;Effect of Standard Deviation on Normal Distribution\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;Density\u0026#34;) plt.grid(True) plt.legend() plt.show() Now we can check that the probability for a value to be within the first sigma is around 68%.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mu = 0 sigma = 1 # Define the standard normal PDF def pdf(x): return (1 / np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2)) # Create x values in the 1σ range x = np.linspace(mu - sigma, mu + sigma, 1000) # dense for accuracy y = pdf(x) # Approximate the integral using the trapezoidal rule prob_1sigma = np.trapezoid(y, x) print(\u0026#34;Approximate probability in 1σ region:\u0026#34;, prob_1sigma) Approximate probability in 1σ region: 0.6826893305001358 Wait, trapezoidal rule ? It\u0026rsquo;s a numerical method of integration, let\u0026rsquo;s see how it looks.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Few points for trapezoidal approximation x_coarse = np.linspace(0, 3, 6) # only 6 points y_coarse = np.exp(-x_coarse**2) # Smooth curve for the real function x_fine = np.linspace(0, 3, 500) y_fine = np.exp(-x_fine**2) # Approximate area using trapezoidal rule area_approx = np.trapezoid(y_coarse, x_coarse) print(\u0026#34;Approx area:\u0026#34;, area_approx) # Plot smooth curve plt.figure(figsize=(8,5)) plt.plot(x_fine, y_fine, \u0026#39;b-\u0026#39;, label=r\u0026#39;$f(x)=e^{-x^2}$ (real curve)\u0026#39;) # Plot trapezoidal approximation plt.plot(x_coarse, y_coarse, \u0026#39;o--\u0026#39;, color=\u0026#39;orange\u0026#39;, label=\u0026#39;Trapezoid tops\u0026#39;) plt.fill_between(x_coarse, 0, y_coarse, alpha=0.3, color=\u0026#39;orange\u0026#39;, label=\u0026#39;Trapezoids\u0026#39;) plt.title(\u0026#34;Trapezoidal Approximation vs Real Curve\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;y\u0026#34;) plt.legend() plt.grid(True) plt.show() Approx area: 0.8861884778115766 Oook so we have the PDF, but if we want the probability at a given point we want the Cumulative Distribution function (CDF). It\u0026rsquo;s the integral of the PDF (the area from $-\\infty$ to $x$)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import numpy as np import matplotlib.pyplot as plt import math # --- PDF and CDF definitions --- def normal_pdf(x, mu=0, sigma=1): return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-(x - mu)**2 / (2*sigma**2)) def normal_cdf_exact(x, mu=0, sigma=1): z = (x - mu) / (sigma * np.sqrt(2)) return 0.5 * (1 + math.erf(z)) # --- Visualization parameters --- mu, sigma = 0, 1 x = np.linspace(-4, 4, 500) pdf = normal_pdf(x, mu, sigma) cdf = [normal_cdf_exact(xi, mu, sigma) for xi in x] # Pick a point to visualize CDF x0 = 1.0 cdf_val = normal_cdf_exact(x0, mu, sigma) plt.figure(figsize=(12,5)) # --- Left: PDF --- plt.subplot(1,2,1) plt.plot(x, pdf, label=\u0026#39;PDF $f(x)$\u0026#39;, color=\u0026#39;blue\u0026#39;) plt.fill_between(x, 0, pdf, where=(x \u0026lt;= x0), color=\u0026#39;blue\u0026#39;, alpha=0.3) plt.axvline(x0, color=\u0026#39;red\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;x = {x0}\u0026#39;) plt.title(\u0026#34;Normal PDF with Area Shaded (CDF at x=1)\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;Density\u0026#34;) plt.legend() plt.grid(True) # Annotate the shaded area with the CDF value plt.text( x0 - 2, max(pdf)*0.7, f\u0026#34;Shaded area = CDF({x0}) ≈ {cdf_val:.3f}\u0026#34;, fontsize=12, color=\u0026#39;blue\u0026#39;, bbox=dict(facecolor=\u0026#39;white\u0026#39;, alpha=0.7) ) # --- Right: CDF --- plt.subplot(1,2,2) plt.plot(x, cdf, label=\u0026#39;CDF $F(x)$\u0026#39;, color=\u0026#39;green\u0026#39;) plt.axhline(cdf_val, color=\u0026#39;red\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;CDF({x0:.1f}) ≈ {cdf_val:.3f}\u0026#39;) plt.axvline(x0, color=\u0026#39;red\u0026#39;, linestyle=\u0026#39;--\u0026#39;) plt.title(\u0026#34;Normal CDF (S-curve)\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;Probability\u0026#34;) plt.legend() plt.grid(True) plt.tight_layout() At that point I kind of forgot what I was looking for in the first place, so I should just go back to the paper and try to make some progress in it.\n","permalink":"https://blog.jmarhic.com/post/2025-07-30-maths-notes-1/","summary":"\u003cp\u003eSo I started reading a paper about diffusion (the original \u003ca href=\"https://arxiv.org/abs/2006.11239\"\u003eDDPM paper\u003c/a\u003e) and I was quickly out of my depth. I needed a refresher about probabilities, and actually even more basic stuff like exponential and integration. And I thought why not share the notes here! So this blog post is the content of a python notebook about exponential and the normal distribution, exported to markdown with \u003ccode\u003ejupyter nbconvert\u003c/code\u003e. It\u0026rsquo;s not deep or anything, just a nice refresher for myself. Kind of a pain to write math formulas and get them displayed in my Jekyll blog but got it working with \u003ca href=\"https://www.mathjax.org/\"\u003eMathjax\u003c/a\u003e.\u003c/p\u003e","title":"Maths notes (1)"},{"content":"Google did me dirty this week and I\u0026rsquo;m salty, so let me tell you. The other day I received an email informing me that my YouTube Premium subscription had been renewed, which surprised me because I canceled it about 6 months ago, and I haven\u0026rsquo;t missed it ever since (thanks, yt-dlp!). I first thought it was my daughter\u0026rsquo;s shenanigans, but after a closer look I had only \u0026ldquo;paused\u0026rdquo; the subscription instead of canceling it, and Google conveniently failed to inform me it was going to be restarted\u0026hellip; No advance email like \u0026ldquo;your subscription will restart in a few days,\u0026rdquo; just \u0026ldquo;whoops, we restarted your subscription and you\u0026rsquo;ve been charged 13 euros, teehee.\u0026rdquo;\nAlright, it\u0026rsquo;s my bad for not canceling outright and just pausing the subscription, right? Why did I not cancel in the first place, actually? Well\u0026hellip; now my memory comes back. The reason I didn\u0026rsquo;t cancel was I didn\u0026rsquo;t manage to the first time I tried. Let\u0026rsquo;s give it another try\u0026hellip; can you find the cancel confirmation button?\nDid you see it? Yes, that\u0026rsquo;s right, it\u0026rsquo;s the dark blue button on the very bottom of the screen, just under the navigation button. So you cannot click it*. Given we\u0026rsquo;re talking about a company that A/B tests shades of blue, there is no way putting a dark blue button on a black background, hidden under the Android navigation keys, was a mistake.\nSo as a retaliation measure against a $2.3 trillion company stealing my 13 euros, I decided to step up my de-Googling efforts this week. I\u0026rsquo;ve changed my default search engine to DuckDuckGo and canceled my €30 Google One subscription. That\u0026rsquo;ll teach them.\nI\u0026rsquo;m already using Firefox with uBlock Origin, so if I get serious about it, the hard next steps will be to switch from Android to GrapheneOS (though I might just get an iPhone next time), and get a new email address (but single sign-on with Gmail is just so convenient\u0026hellip;).\n*If you have the same issue, put your phone in landscape mode and scroll down; that should do the trick.\n","permalink":"https://blog.jmarhic.com/post/2025-07-25-i-apologize-for-the-confusion-you-re-absolutely-right/","summary":"\u003cp\u003eGoogle did me dirty this week and I\u0026rsquo;m salty, so let me tell you. The other day I received an email informing me that my YouTube Premium subscription had been renewed, which surprised me because I canceled it about 6 months ago, and I haven\u0026rsquo;t missed it ever since (thanks, \u003ca href=\"https://github.com/yt-dlp/yt-dlp\"\u003eyt-dlp\u003c/a\u003e!). I first thought it was my daughter\u0026rsquo;s shenanigans, but after a closer look I had only \u0026ldquo;paused\u0026rdquo; the subscription instead of canceling it, and Google conveniently failed to inform me it was going to be restarted\u0026hellip; No advance email like \u0026ldquo;your subscription will restart in a few days,\u0026rdquo; just \u0026ldquo;whoops, we restarted your subscription and you\u0026rsquo;ve been charged 13 euros, teehee.\u0026rdquo;\u003c/p\u003e","title":"I apologize for the confusion. You're absolutely right."},{"content":"Just a quick update to say I am still making progress on the Password Game Agent project I mentioned last post. I have now reached up to step 16 where we need to solve a chess position\u0026hellip; Seems like a suitable job for a reasoning model !\nThe main changes that enabled going from step 11 (Wordle answer) to 16 were adding a \u0026ldquo;search tool\u0026rdquo; based on OpenAI web search tool and changing the reasoning effort from \u0026ldquo;medium\u0026rdquo; to \u0026ldquo;high\u0026rdquo;. The current version of the code is here : https://github.com/goverture/password-game-agent/blob/master/manually.py I\u0026rsquo;m still making regular changes and trying new ideas to make progress. I\u0026rsquo;ve noticed we often seem to get stuck for various reason (for instance a badly recognized Capcha), so I want to add a new step to ensure that we make progress consistently, or backtrack, in order to not get stuck.\n","permalink":"https://blog.jmarhic.com/post/2025-07-05-july-update/","summary":"\u003cp\u003eJust a quick update to say I am still making progress on the Password Game Agent project I mentioned last post. I have now reached up to step 16 where we need to solve a chess position\u0026hellip; Seems like a suitable job for a reasoning model !\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Step 16 of the password game require solving a chess puzzle.\" loading=\"lazy\" src=\"/assets/images/password_game_step16.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThe main changes that enabled going from step 11 (Wordle answer) to 16 were adding a \u0026ldquo;search tool\u0026rdquo; based on \u003ca href=\"https://platform.openai.com/docs/guides/tools-web-search\"\u003eOpenAI web search tool\u003c/a\u003e and changing the reasoning effort from \u0026ldquo;medium\u0026rdquo; to \u0026ldquo;high\u0026rdquo;.\nThe current version of the code is here : \u003ca href=\"https://github.com/goverture/password-game-agent/blob/master/manually.py\"\u003ehttps://github.com/goverture/password-game-agent/blob/master/manually.py\u003c/a\u003e I\u0026rsquo;m still making regular changes and trying new ideas to make progress. I\u0026rsquo;ve noticed we often seem to get stuck for various reason (for instance a badly recognized Capcha), so I want to add a new step to ensure that we make progress consistently, or backtrack, in order to not get stuck.\u003c/p\u003e","title":"July Update"},{"content":"There is this javascript game called The Password Game where you have to chose a password, following increasingly ludicrous requirements. Agentic coding/research is all the rage today and I got the idea of making an \u0026ldquo;agent\u0026rdquo; that would solve it. Conceptually it\u0026rsquo;s just about calling a LLM in a loop, giving it the proper tools and context until it solved the task at hand.\nHere\u0026rsquo;s where I got so far, using ChatGPT 4o and Playwright MCP (only gave it the navigate and type tools for now). It\u0026rsquo;s solving correctly the first few steps, but gets stuck at the \u0026ldquo;sponsor\u0026rdquo; rule because it cannot view the image. The next step is to give it access to the playwright\u0026rsquo;s screenshot tool. Let\u0026rsquo;s see how far it can go !\nOn an unrelated note, my company finally decided to self host a model ! We are going for vLLM+Skypilot. Pretty excited about the possibilities here, though hosting on AWS is expensive and I have doubts about the return on interest (last time I did the math, it was basically impossible to beat gpt-4o-mini pricing on token/$, so let\u0026rsquo;s hope the quality is there and that we can migrate to a cheaper GPU provider).\nEdit: June 29th Alright a quick update on the password game, I now pass a screenshot after each step and with a little bit of context engineering, and adding an extra thinking step with o4-mini, I was able to consistently clear the \u0026ldquo;sponsor\u0026rdquo; image step (as well as the captcha step !). I reached up to step 11, which requires knowing \u0026ldquo;Today\u0026rsquo;s Wordle answer\u0026rdquo;\u0026hellip; gonna be hard to solve ! I think I need a different approach for this one (multi agent ?), where I can delegate a subtask to be cleared by a different agent (ie \u0026ldquo;find today\u0026rsquo;s wordle answer\u0026rdquo; using search and navigation). I\u0026rsquo;ll see if I can use the OpenAI Agent SDK to make progress.\n","permalink":"https://blog.jmarhic.com/post/2025-06-18-the-password-game-agent/","summary":"\u003cp\u003eThere is this javascript game called \u003ca href=\"https://neal.fun/password-game/\"\u003eThe Password Game\u003c/a\u003e where you have to chose a password, following increasingly ludicrous requirements.\nAgentic coding/research is all the rage today and I got the idea of making an \u0026ldquo;agent\u0026rdquo; that would solve it. Conceptually it\u0026rsquo;s just about calling a LLM in a loop, giving it the proper tools and context until it solved the task at hand.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s where I got so far, using ChatGPT 4o and \u003ca href=\"https://github.com/microsoft/playwright-mcp\"\u003ePlaywright MCP\u003c/a\u003e (only gave it the navigate and type tools for now). It\u0026rsquo;s solving correctly the first few steps, but gets stuck at the \u0026ldquo;sponsor\u0026rdquo; rule because it cannot view the image. The next step is to give it access to the playwright\u0026rsquo;s screenshot tool. Let\u0026rsquo;s see how far it can go !\u003c/p\u003e","title":"The password game agent"},{"content":"Another May update ! Not much going on as usual, rainy season arrived in Ho Chi Minh city so we get some strong rain and nice sunsets.\nYesterday we got the announcement that Pocket was saying goodbye. Kind of bummed because I found the service convenient, though I just used it as a link bookmark (I never cared much about the reading mode, I always go to the original link - though apparently that worked well with the Kobo e-reader). Anyway I switched to a self-hosted alternative immediately: Wallabag. It\u0026rsquo;s kind of sluggish but it does the job, and it has an Android app so I can still \u0026ldquo;share link\u0026rdquo; to save a link from my phone.\nThat brings my current self hosted service collection to:\nWallabag (Read-it later) Pihole (DNS) Miniflux (RSS) Prometheus/Graphana Jellyfin (Media) Openwebui (AI Chatbot) Anyway, I was importing my old pocket saves into my new Wallabag setup (I\u0026rsquo;ve got a script to import your links from Pocket here) and I found an old save from Russ Cox\u0026rsquo;s blog, Regular Expression Matching Can Be Simple And Fast . It has this scary looking graph for a not so scary looking regex:\nI decided to check if that was true (or at least still the case) with that code:\n1 2 3 4 5 6 7 8 9 require \u0026#39;benchmark\u0026#39; n = 33 regex = Regexp.new(\u0026#34;a?\u0026#34; * n + \u0026#34;a\u0026#34; * n) str = \u0026#34;a\u0026#34; * n time = Benchmark.realtime do puts regex.match?(str) end Not sure about Ruby 1.8, but indeed on Ruby 2.7.2, the above took around 30 seconds to execute. The good news is that it got fixed in Ruby 3.2 and this is now pretty much instant !\nNot much else going on, on the AI front recently I gave Lovable a try and it makes nice designs, but I don\u0026rsquo;t have a project idea at the moment. In the past few weeks there has been so many new product release and model updates that I kind of checked out\u0026hellip; Are Google AI Studio and Firebase Studio two different things ? OpenAI Codex is a cool name, but it used to be the original copilot code completion model right right ?? And one month after VSCode adds \u0026ldquo;Agent mode\u0026rdquo; to copilot, we get Github Copilot coding agent ??? Come on.\nAnyway, so far I\u0026rsquo;m happy with my oldschool VSCode + Copilot Agent based workflow. At work, people have been onboarding Devin but I\u0026rsquo;m still waiting to be wowed (I\u0026rsquo;m doubtful this will happen, as long as you need to describe in minute details the task to perform, then it\u0026rsquo;s faster to go ahead and do it yourself). But things are clearly moving fast toward a \u0026ldquo;github based\u0026rdquo; agent workflow where an external service clones your repo and make entire pull requests for you, can\u0026rsquo;t say I\u0026rsquo;m thrilled.\n","permalink":"https://blog.jmarhic.com/post/2025-05-25-may-update/","summary":"\u003cp\u003eAnother May update ! Not much going on as usual, rainy season arrived in Ho Chi Minh city so we get some strong rain and nice sunsets.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Rainy season sunset\" loading=\"lazy\" src=\"/assets/images/sunset.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eYesterday we got the announcement that \u003ca href=\"https://support.mozilla.org/en-US/kb/future-of-pocket\"\u003ePocket was saying goodbye\u003c/a\u003e. Kind of bummed because I found the service convenient, though I just used it as a link bookmark (I never cared much about the reading mode, I always go to the original link - though apparently that worked well with the Kobo e-reader). Anyway I switched to a self-hosted alternative immediately: \u003ca href=\"https://wallabag.org/\"\u003eWallabag\u003c/a\u003e. It\u0026rsquo;s kind of sluggish but it does the job, and it has an Android app so I can still \u0026ldquo;share link\u0026rdquo; to save a link from my phone.\u003c/p\u003e","title":"May update"},{"content":"So MCP is all the rage these days, and it\u0026rsquo;s not very complex: it\u0026rsquo;s basically a standardized way to provide tools to LLMs. So you have an RPC server that provides a description of the tools and the parameters they expect, and your client (a LLM based application) can connect to it and tell the LLM what tools are available, and the LLM can decide to call them when appropriate. Easy stuff and the SDK provided do most of the heavy lifting.\nSo in order to give it a try I made a simple \u0026ldquo;Random number\u0026rdquo; MCP server in typescript. The idea being that the LLM would call it when asked to generate a random number. Apparently VSCode agent only supports \u0026ldquo;tools\u0026rdquo; and not \u0026ldquo;resources\u0026rdquo; at the moment, and also they only support the legacy \u0026ldquo;SSE\u0026rdquo; transport type (by opposition to the newest StreamableHttp) so I added support for both (basically you get two endpoints, /mcp for StreamableHttp and /sse for SSE). And then you can connect your server to multiple different clients ! I tried with VSCode copilot agent, the local MCP inspector tool and the online Cloudflare AI Playground.\nHere\u0026rsquo;s how it looked:\nfrom VSCode Copilot (agent mode) from locally hosted MCP Inspector from the Cloudflare AI Playground For the Cloudflare Playground, I hosted my server online with Fly.io, at https://random-mcp.fly.dev/. Feel free to use it if you need a random number :) Fly.io became my favorite way to spin up a quick backend ! And it\u0026rsquo;s free while my monthly bill is under 5$, which is super nice of them.\nMy secret to free infra ? Having no user and no traffic on my apps. Anyway, as expected HackerNews is bearish about MCP, but it\u0026rsquo;s pretty nice to finally have a standardized way to create and expose tools to the LLM. It\u0026rsquo;s super easy technically, we\u0026rsquo;ll see if it makes sense to use them in our products.\nNB: Re-reading my post, I noticed I insisted quite a bit on the \u0026ldquo;easy\u0026rdquo; part, mentioning it 3 times in total. It\u0026rsquo;s because I got a grand total of 1 hour of free time this week and that was enough to get my prototype deployed and working.\n","permalink":"https://blog.jmarhic.com/post/2025-05-04-my-first-mcp-server/","summary":"\u003cp\u003eSo MCP is all the rage these days, and it\u0026rsquo;s not very complex: it\u0026rsquo;s basically a standardized way to provide tools to LLMs. So you have an RPC server that provides a description of the tools and the parameters they expect, and your client (a LLM based application) can connect to it and tell the LLM what tools are available, and the LLM can decide to call them when appropriate. Easy stuff and the \u003ca href=\"https://github.com/modelcontextprotocol/typescript-sdk\"\u003eSDK provided\u003c/a\u003e do most of the heavy lifting.\u003c/p\u003e","title":"My First MCP server"},{"content":"Unsurprisingly with a newborn and a very sticky 3 years old at home, I haven\u0026rsquo;t been doing much in the past 3 weeks. Since I stopped working on it, I\u0026rsquo;ve released my thematic crossword generation app, Prosettr, to a complete (and expected) indifference (zero traffic came from the HackerNews announcement, and I got about 10 likes from LinkedIn). Oh well, it was a fun project anyway and I\u0026rsquo;m quite happy with the result!\nWhen getting ready for release I was considering my hosting options - GCP Cloud Run kind of rugged pull me with their CPU and memory quotas being way too low! And I was not going to beg them for a quota increase. Luckily, Fly.io saved the day with their super easy to use fly machines. My app requires a lot of CPU and memory (4cpu, 16 Gb of RAM) in very short bursts - just a few seconds when the user is doing a solve. I made a simple \u0026ldquo;controller\u0026rdquo; endpoint that starts and stops \u0026ldquo;solver\u0026rdquo; machines on demand, for that. The Fly.io API was a pleasure to work with, and it\u0026rsquo;s nice to be able to connect via a wireguard network.\nHere is the code of the controller endpoint for later reference: Fly.io controller endpoint in go. With that, I get a fleet of solver machines (I scaled to 8), and a single controller machine start them and proxies the websocket connection. I put it together in an evening and was pleased with the results. Fly machines really do start in a few milliseconds! I\u0026rsquo;ll use them in my next project, whatever that may be.\nMoving on, VSCode finally released their MCP support! I\u0026rsquo;ve been eyeing MCP stuff for a while but I didn\u0026rsquo;t have a MCP client (think Claude Code or Cursor) to play with. Now I have one with Copilot Agent! I asked our Infra team to enable the Copilot \u0026ldquo;Preview Features\u0026rdquo; for our organization, otherwise the MCP Servers didn\u0026rsquo;t appear in the list somehow.\nI followed a video tutorial on youtube and got the Postgres MCP working locally. It seems promising, I\u0026rsquo;ll have to play more with it.\nI\u0026rsquo;ll close with a generated image of Nvidia\u0026rsquo;s CEO as a lego figurine, the new ChatGPT image generation rocks!\n","permalink":"https://blog.jmarhic.com/post/2025-04-12-april-update/","summary":"\u003cp\u003eUnsurprisingly with a newborn and a very sticky 3 years old at home, I haven\u0026rsquo;t been doing much in the past 3 weeks. Since I stopped working on it, I\u0026rsquo;ve released my thematic crossword generation app, \u003ca href=\"https://prosettr.com\"\u003eProsettr\u003c/a\u003e, to a complete (and expected) indifference (zero traffic came from the \u003ca href=\"https://news.ycombinator.com/item?id=43521279\"\u003eHackerNews announcement\u003c/a\u003e, and I got about 10 likes from LinkedIn). Oh well, it was a fun project anyway and I\u0026rsquo;m quite happy with the result!\u003c/p\u003e","title":"April update"},{"content":"My son Liam was born this Monday! He is healthy and everything is good. I haven\u0026rsquo;t touched the computer for the week, and as a result I don\u0026rsquo;t have anything technical to share.\nThe week before however I gave a try to Browser Use, a tool that allows LLMs to use the browser more effectively. I haven\u0026rsquo;t read in detail how it works but it seems to highlight the interactive areas (buttons etc.) and then take a screenshot for analysis, instead of only sending the DOM as text. It worked pretty well, I was able to fill a form entirely with it (prompting it to not press submit!), and to use Google Translate as well. I don\u0026rsquo;t have a special use case idea for it at the moment.\nFor the past few weeks, Claude Plays Pokemon on Twitch has been featuring Claude 3.7 trying to beat Pokemon Red. Haven\u0026rsquo;t followed closely, I know there were a couple of restarts as the developer added more tools (like memory etc.) to help the model through the game. It\u0026rsquo;s apparently not going too well at the moment\u0026hellip;\nBut it reminded me of the old OpenAI Gym (back when they shared their research, I guess because it didn\u0026rsquo;t work at the time), a framework with some Atari-style games to train models to play. Apparently it got forked into Gymnasium and it is still maintained.\nI was wondering how ChatGPT would perform on it so I made a small script that takes screenshots (every N frames) and prompts ChatGPT for actions in the Lunar Lander minigame. The goal is to land the lander softly and straight\u0026hellip; It\u0026rsquo;s not going too well either for me so far! At the time of OpenAI Gym, the main approach was to give unlabelled data to the model and let it figure out what the input and output mean through countless observation steps, figuring out a winning strategy just via the reward. I\u0026rsquo;ve never really liked that approach, I wouldn\u0026rsquo;t do well piloting a helicopter with unlabelled buttons either. So I\u0026rsquo;m giving ChatGPT more info (like what the actions mean etc.).\nHere\u0026rsquo;s a sample of output.\nThe model justification is: The lander is still off-center and moving further right, so we should continue using the left orientation engine to correct its position. No further main engine use is needed immediately as the descent speed seems stable after the last adjustment.\nGPT-4o Recommendation for frame 50: [1, 1, 0, 0, 0]\nThe model justification is: The lander continues its drift to the right, making it important to correct this trajectory. Continuing to fire the left orientation engine will help pull the lander back on course. Since the descent speed seems manageable, focus remains on correction, not slowing down.\nGPT-4o Recommendation for frame 55: [1, 1, 0, 0, 0]\nThe model justification is: The lander is still drifting noticeably to the right. Continuing to fire the left orientation engine is necessary to counter this drift. Monitoring for any changes in position or speed is crucial, particularly with it being closer to the surface.\nGPT-4o Recommendation for frame 60: [1, 1, 0, 0, 0]\nThe model justification is: The lander is continuing to move right, so further correction using the left orientation engine is necessary. Ensuring it aligns back to the center is the priority. Monitoring speed is still crucial but maintaining focus on significant lateral drift correction is key.\nThe output makes sense on its own, but not with regard to the given screenshots\u0026hellip; So far I have not been able to land safely !\n","permalink":"https://blog.jmarhic.com/post/2025-03-23-welcome-to-liam/","summary":"\u003cp\u003eMy son Liam was born this Monday! He is healthy and everything is good. I haven\u0026rsquo;t touched the computer for the week, and as a result I don\u0026rsquo;t have anything technical to share.\u003c/p\u003e\n\u003cp\u003eThe week before however I gave a try to \u003ca href=\"https://browser-use.com/\"\u003eBrowser Use\u003c/a\u003e, a tool that allows LLMs to use the browser more effectively. I haven\u0026rsquo;t read in detail how it works but it seems to highlight the interactive areas (buttons etc.) and then take a screenshot for analysis, instead of only sending the DOM as text. It worked pretty well, I was able to fill a form entirely with it (prompting it to not press submit!), and to use Google Translate as well. I don\u0026rsquo;t have a special use case idea for it at the moment.\u003c/p\u003e","title":"Welcome to Liam"},{"content":"Not much going on these days. At work, we started migrating some apps from Google App Engine to AWS, which gave me a chance to learn about AWS CDK. As a learning step, I\u0026rsquo;ve made a small template to deploy a static website on S3 + CloudFront for the frontend and ALB + ECS for the backend, with some CloudFront behaviors, Route 53, and ACM certificates sprinkled in. As far as I know, it\u0026rsquo;s a standard architecture (though I need to lock down the S3 permissions a bit more, add logs to CloudWatch, etc.), and it\u0026rsquo;s really nice that it is reviewable by our security guy before we deploy it. And also, it can be deployed to staging first and later on to production with little to no changes.\nIn the past, I\u0026rsquo;ve been annoyed when writing a Lambda in staging and having to duplicate it in the production environment (a separate AWS account). This would solve those kinds of issues. Overall, I\u0026rsquo;m really pleased with the experience (especially given that the alternative was writing CloudFormation templates by hand or registering resources in the AWS console\u0026hellip;). I didn\u0026rsquo;t look too closely into the generated CloudFormation templates, but it\u0026rsquo;s nice to be able to destroy and redeploy at will when something goes wrong.\nA few gotchas that bit me before I got it to work:\nFirst, I couldn\u0026rsquo;t create a VPC because we were exceeding the \u0026ldquo;Elastic IP\u0026rdquo; limit (5 per account per the AWS Doc), so I just reused an existing VPC. I didn\u0026rsquo;t have a health check endpoint in the backend code originally, so the service kept restarting and the deploy never completed successfully. We must have a /health (or /) endpoint reachable. The ACM for CloudFront must be issued in \u0026ldquo;us-east-1\u0026rdquo;? That one was super bullshit. Given that I made my template during the weekend, I\u0026rsquo;m open-sourcing it here: CDK Template - the stack definition itself is here. It deploys a single index.html page to S3 and CloudFront, registers some subdomains and SSL certificates, and deploys a load balancer and a container on ECS (using the ApplicationLoadBalancedFargateService construct) for a small Go app (a click counter).\n","permalink":"https://blog.jmarhic.com/post/2025-03-09-trying-cdk-and-k6/","summary":"\u003cp\u003eNot much going on these days. At work, we started migrating some apps from Google App Engine to AWS, which gave me a chance to learn about \u003ca href=\"https://docs.aws.amazon.com/cdk/v2/guide/home.html\"\u003eAWS CDK\u003c/a\u003e. As a learning step, I\u0026rsquo;ve made a small template to deploy a static website on S3 + CloudFront for the frontend and ALB + ECS for the backend, with some CloudFront behaviors, Route 53, and ACM certificates sprinkled in. As far as I know, it\u0026rsquo;s a standard architecture (though I need to lock down the S3 permissions a bit more, add logs to CloudWatch, etc.), and it\u0026rsquo;s really nice that it is reviewable by our security guy before we deploy it. And also, it can be deployed to staging first and later on to production with little to no changes.\u003c/p\u003e","title":"First steps with CDK"},{"content":"February went by in a blink! I barely had any time for myself this month between work, a pregnant wife, and my 2-year-old being in the \u0026ldquo;I want papa only\u0026rdquo; phase. These days, the first thing I do in the morning is play Lego. It beats doomscrolling, but at 7 a.m. and before my coffee, it\u0026rsquo;s tough to be creative. Here\u0026rsquo;s an elephant I made this morning—the trunk moves.\nI\u0026rsquo;ve also rewritten a big part of the backend of Prosettr.com. In a HackerNews thread about Donald Knuth (Donald Knuth\u0026rsquo;s 2024 Christmas Lecture: Strong and Weak Components), I learned there was an improvement to the algorithm that my app is based on, Dancing Links. I\u0026rsquo;m not going to go into much detail here (maybe in a future post), but I procured The Art of Computer Programming Volume 4B, and indeed, the improved version uses half the memory, with each option\u0026rsquo;s items having only up and down links, and no left and right links—those being replaced by a \u0026ldquo;spacer\u0026rdquo; node. Here\u0026rsquo;s my original implementation in Go I made while following the chapter: /backtrack_aocp/main.go. Then I replaced the previous implementation with this one, with some added optimizations (support for secondary columns, using channels instead of an input matrix, another channel to output the solutions, etc.).\nThe best part of the algorithm is that, even though the book describes the links between nodes as \u0026ldquo;pointers,\u0026rdquo; they really are just an offset into the Node array. This makes copying the structure super easy, which in turn enables parallelizing the search process! It\u0026rsquo;s still not perfect, but here\u0026rsquo;s what I have at the moment.\nThe other advantage is that, since it\u0026rsquo;s an offset and not a pointer, I can actually choose to use int32 (instead of 64-bit pointers) and halve the memory usage again! I just defined type AppInt int32 and used that instead of int for the offsets. It works as long as you have fewer than 2 billion nodes—I have around 100 million for a 21x21 crossword, so I\u0026rsquo;m safe.\nIn a few seconds, you can generate a crossword using as many thematic words as possible.\nLastly, I\u0026rsquo;ve started using Aider (\u0026ldquo;Aider is AI pair programming in your terminal\u0026rdquo;). I\u0026rsquo;ve been feeling more and more FOMO recently with the newest LLM releases (Claude 3.7 and GPT-4.5 just this week) and the various agentic tools (Cursor\u0026rsquo;s Composer, Claude Code\u0026hellip;). I want to give them a proper try, but I\u0026rsquo;m not ready to give up control of my workflow. I\u0026rsquo;m actually using Aider with git commit disabled (eg --no-git), as I prefer to view the diff before committing. It went well so far—I\u0026rsquo;ve been able to save quite some time (compared to copy-pasting to and from ChatGPT). For some reason, it sometimes edits the wrong part of the code though (I saw it editing the wrong CI job definition and the wrong test, but with correct code—I just had to manually move it).\nLet\u0026rsquo;s see, what else? Andrej Karpathy just released a video titled How I use LLMs, which threw me back to my earlier, pretty half-assed blog post: [How I use GitHub Copilot]({% post_url 2024-12-25-how-i-use-github-copilot %}). Curious to see how my programming process will evolve this year. I\u0026rsquo;ve been following G. Huntley\u0026rsquo;s posts about Cursor and the future of programming (see https://ghuntley.com/ngmi/ for instance) about the necessity of embracing LLM-powered programming, and anyway, it\u0026rsquo;s a pretty exciting development to follow. It has been humbling to realize a machine can do a better job than me at writing code—and frankly, it\u0026rsquo;s a good thing. Looking back to my earlier programming days, I don\u0026rsquo;t miss searching Stack Overflow or some API docs to find out what flags to pass to append to a file or such trivialities, and I get more time to focus on the big picture. OK It\u0026rsquo;s almost midnight, so I\u0026rsquo;m going to stop here and push the post before we move to March!\n","permalink":"https://blog.jmarhic.com/post/2025-02-28-february-update/","summary":"\u003cp\u003eFebruary went by in a blink! I barely had any time for myself this month between work, a pregnant wife, and my 2-year-old being in the \u0026ldquo;I want papa only\u0026rdquo; phase. These days, the first thing I do in the morning is play Lego. It beats doomscrolling, but at 7 a.m. and before my coffee, it\u0026rsquo;s tough to be creative. Here\u0026rsquo;s an elephant I made this morning—the trunk moves.\u003c/p\u003e\n\u003cdiv style=\"text-align: center;\"\u003e\n    \u003cimg src=\"/assets/images/lego_elephant.jpg\" alt=\"An elephant in Lego\" width=\"300\"\u003e\n\u003c/div\u003e\n\u003cp\u003eI\u0026rsquo;ve also rewritten a big part of the backend of \u003ca href=\"https://prosettr.com\"\u003eProsettr.com\u003c/a\u003e. In a HackerNews thread about Donald Knuth (\u003ca href=\"https://news.ycombinator.com/item?id=42970240\"\u003eDonald Knuth\u0026rsquo;s 2024 Christmas Lecture: Strong and Weak Components\u003c/a\u003e), I learned there was an improvement to the algorithm that my app is based on, Dancing Links. I\u0026rsquo;m not going to go into much detail here (maybe in a future post), but I procured \u003cem\u003eThe Art of Computer Programming\u003c/em\u003e Volume 4B, and indeed, the improved version uses half the memory, with each option\u0026rsquo;s items having only up and down links, and no left and right links—those being replaced by a \u0026ldquo;spacer\u0026rdquo; node. Here\u0026rsquo;s my original implementation in Go I made while following the chapter: \u003ca href=\"https://github.com/goverture/exact_cover/blob/master/examples/backtrack_aocp/main.go\"\u003e/backtrack_aocp/main.go\u003c/a\u003e. Then I replaced the previous implementation with this one, with some added optimizations (support for secondary columns, using channels instead of an input matrix, another channel to output the solutions, etc.).\u003c/p\u003e","title":"February update"},{"content":"So I just got a Galaxy S 23 FE phone to replace my recently lost Realme crapphone. And\u0026hellip; frankly, it\u0026rsquo;s not much better. It came loaded with a LOT of bloat: Samsung apps (Galaxy Shop?), Microsoft apps (Copilot, Linkedin\u0026hellip;), Netflix, and a bunch of crapware like \u0026ldquo;AR Doodle\u0026rdquo;, \u0026ldquo;AR Emoji\u0026rdquo; that are somehow running in the background. Of course, I cannot uninstall any of those without rooting my phone, if it\u0026rsquo;s even possible.\nGoing to the Play Store to download \u0026ldquo;Google Translate\u0026rdquo; that somehow wasn\u0026rsquo;t installed by default, the experience is that some random app appears first as an ad, using almost the exact icon:\nThe whole experience seems super cheap\u0026hellip; I\u0026rsquo;ve always owned only Android phones, but I can totally understand the success of the iPhone. Google makes money on the ads so it can provide the OS for free, but the resulting experience between the ads and the manufacturers\u0026rsquo; overlays is really, really poor.\nAnyway, I am going to check if I can root the phone and remove all this crap. I still have to install Graphene on my old Pixel 4a as well.\n","permalink":"https://blog.jmarhic.com/post/2025-02-14-google-ads/","summary":"\u003cp\u003eSo I just got a Galaxy S 23 FE phone to replace my recently lost Realme crapphone. And\u0026hellip; frankly, it\u0026rsquo;s not much better. It came loaded with a LOT of bloat: Samsung apps (Galaxy Shop?), Microsoft apps (Copilot, Linkedin\u0026hellip;), Netflix, and a bunch of crapware like \u0026ldquo;AR Doodle\u0026rdquo;, \u0026ldquo;AR Emoji\u0026rdquo; that are somehow running in the background. Of course, I cannot uninstall any of those without rooting my phone, if it\u0026rsquo;s even possible.\u003c/p\u003e","title":"Fed up with Google ads"},{"content":"Pretty good start to the year overall, I\u0026rsquo;ve managed to keep writing blog posts regularly. Not sure if anyone is reading them as there is no comment system and I don\u0026rsquo;t have any analytics set up yet, but it doesn\u0026rsquo;t matter for now—I\u0026rsquo;m just trying to get better at writing first. Mostly, I\u0026rsquo;m writing them as a memento, something I can look back on in the future, and also for the chance of influencing future LLMs, if only a tiny bit, with some of myself. I enjoyed a blog post about it recently, AI Slop, Suspicion, and Writing Back by Ben Congdon.\nI think there is value in mildly influencing the weights of the shoggoth by putting more of your (non-AI-assisted) thoughts out there.\nI made good progress on Baba Is You! I actually solved the remaining worlds I was stuck at, and (just found out you can do \u0026ldquo;spoiler tags\u0026rdquo; with Jekyll)\nClick to reveal the spoiler Accessed the \"secret world,\" which seems to be a compilation of early ideas, as well as levels from other contributors? Not quite sure, but it's very enjoyable, and I'll read more about it once I complete this last world. I continued working on my crossword generation app, Prosettr.com. It\u0026rsquo;s online already, but I\u0026rsquo;m not quite happy with the UI yet. It\u0026rsquo;s good enough for release, so I\u0026rsquo;ll just add some dark mode, fix the UI bugs, and try to do a Show HN post for launch. I even added some AI (a call to Gemini 2.0 Flash to generate words related to a given theme)! Struggling a bit with the frontend layout, also lost time rewriting from using \u0026ldquo;props\u0026rdquo; to using \u0026ldquo;Vuex\u0026rdquo; and finally \u0026ldquo;Pinia\u0026rdquo; for the data store.\nI\u0026rsquo;ve attempted to improve the word list by rating the words with an LLM. I used the recent Microsoft Phi-4 model, which promised good results for 14B weights. I chose that model because I expected better results than with a 7B model, and 14B occupies roughly 28 GB of VRAM, so it fits nicely on an A100 GPU with plenty of room left for the KV cache.\nI used vLLM offline batched inference. I coupled it with guided decoding to ensure I got a proper JSON result. vLLM really flies—I was getting around 2000 tokens/sec. It still took around 10 hours (~$15) to process all 170k words of my list. The code and results are available in the goverture/llm_word_rating repo. Looking back, I could have put more effort into the prompt or generated a definition for each word. I also saw some weird results, like Phi-4 misreading the word \u0026ldquo;YOURIDEALWEIGHT\u0026rdquo; as \u0026ldquo;YOURIDEALWEALTH\u0026rdquo; or \u0026ldquo;LEGHORNS\u0026rdquo; as \u0026ldquo;LEGO.\u0026rdquo; But I suppose it\u0026rsquo;s alright—if the word is so uncommon that Phi-4 misreads it, it\u0026rsquo;s probably not worth having in the list. Anyway, I use the resulting list in Prosettr.com, filtering out words rated below 20.\n","permalink":"https://blog.jmarhic.com/post/2025-02-03-january-2025-retrospective/","summary":"\u003cp\u003ePretty good start to the year overall, I\u0026rsquo;ve managed to keep writing blog posts regularly. Not sure if anyone is reading them as there is no comment system and I don\u0026rsquo;t have any analytics set up yet, but it doesn\u0026rsquo;t matter for now—I\u0026rsquo;m just trying to get better at writing first. Mostly, I\u0026rsquo;m writing them as a memento, something I can look back on in the future, and also for the chance of influencing future LLMs, if only a tiny bit, with some of myself. I enjoyed a blog post about it recently, \u003ca href=\"https://benjamincongdon.me/blog/2025/01/25/AI-Slop-Suspicion-and-Writing-Back\"\u003eAI Slop, Suspicion, and Writing Back by Ben Congdon\u003c/a\u003e.\u003c/p\u003e","title":"January 2025 retrospective"},{"content":"Two days ago, OpenAI released their latest model, OpenAI o3-mini, a follow-up to the reasoning models o1 and o1-mini. They were immediately available on chatgpt.com, so I had a chance to put them to work. I had a simple task in mind (writing a Python script that would prompt an LLM to rate a list of words for use in my crossword app, prosettr.com). The first output was good, but when I asked for a few minor tweaks I was presented with a refusal:\nYour request was flagged as potentially violating our usage policy. Please try again with a different prompt.\nI guess it\u0026rsquo;s due to OpenAI trying to hide their own model\u0026rsquo;s chain of thought, but here I was just asking for a prompt tweak in my script, not trying to get OpenAI\u0026rsquo;s secret sauce.\nLater on, I decided to use vLLM\u0026rsquo;s \u0026ldquo;offline batched inference\u0026rdquo; instead of the server mode, so I asked for the corresponding change. And\u0026hellip; for some reason it refused again?\nThe optics are pretty ugly on that one: It\u0026rsquo;s a policy violation to replace OpenAI\u0026rsquo;s by vLLM calls now? To be fair, after I insisted it gave a second thought and acceded to my request, but it felt more like\u0026hellip; not sure how to say it, like a customer service doing me a favor just for this time, rather than a tool being reliable. But I think it\u0026rsquo;s clear that the censor model used by OpenAI is too restrictive, getting in the way of real work done. And it makes me glad for open-source LLMs existing, a future where some reasonable requests like \u0026ldquo;use a competitor\u0026rdquo; are flagged is not unimaginable.\nSo, mixed feelings on o3-mini so far. I haven\u0026rsquo;t noticed an obvious quality difference compared to o1-mini, I\u0026rsquo;m happy with the increased message rate limit, but I\u0026rsquo;ll switch to Claude or Deepseek the next time I see a refusal.\n","permalink":"https://blog.jmarhic.com/post/2025-02-02-openai-o3-mini-first-impressions/","summary":"\u003cp\u003eTwo days ago, OpenAI released their latest model, \u003ca href=\"https://openai.com/index/openai-o3-mini/\"\u003eOpenAI o3-mini\u003c/a\u003e, a follow-up to the reasoning models o1 and o1-mini. They were immediately available on chatgpt.com, so I had a chance to put them to work. I had a simple task in mind (writing a Python script that would prompt an LLM to rate a list of words for use in my crossword app, \u003ca href=\"https://prosettr.com\"\u003eprosettr.com\u003c/a\u003e). The first output was good, but when I asked for a few minor tweaks I was presented with a refusal:\u003c/p\u003e","title":"OpenAI o3-mini first impressions"},{"content":"This week it\u0026rsquo;s Lunar New Year, or Têt celebrations in Vietnam. Which means my daughter\u0026rsquo;s school is off, which means I get approximately 30 seconds of free time per day. Despite that, it was hard to miss the hype regarding the release of Deepseek R1. I didn\u0026rsquo;t have time to read the paper or anything, but I gave it a quick try at chat.deepseek.com. I still don\u0026rsquo;t have a good handle on what is a good \u0026ldquo;reasoning question,\u0026rdquo; but I came up with a good use case today: coming up with a memorable port number for a service I\u0026rsquo;m hosting locally.\nCan you come up with a good, 4-number goroawase for a port number? I want to host an RSS reader (Miniflux), so something related to reading/RSS/blogs if possible (otherwise it\u0026rsquo;s okay).\n(Goroawase is Japanese wordplay with numbers, more on Wikipedia). Contrary to OpenAI, which hides them, it was fun seeing the model\u0026rsquo;s thoughts - in total, the model thought for 94 seconds. Here are a few excerpts of the thoughts:\nFirst, let\u0026rsquo;s think about keywords related to RSS readers. Words like read, feed, blog, news, article, subscribe, update, etc. Now, map these to possible Japanese number pronunciations. For example, \u0026ldquo;read\u0026rdquo; might be associated with \u0026ldquo;yo\u0026rdquo; (4) since \u0026ldquo;yo\u0026rdquo; can mean \u0026ldquo;read\u0026rdquo; in some contexts. Looking for combinations. For example, \u0026ldquo;read\u0026rdquo; might be 4 (yo) as in \u0026ldquo;yomu.\u0026rdquo; \u0026ldquo;Feed\u0026rdquo; in Japanese is \u0026ldquo;fīdo\u0026rdquo; (フィード), so maybe 4 (fu?) Hmm, maybe not. Alternatively, \u0026ldquo;RSS\u0026rdquo; could be R-S-S, which might correspond to numbers like 1 (ichi for \u0026lsquo;i\u0026rsquo;), but not sure. Alternatively, \u0026ldquo;blog\u0026rdquo; is \u0026ldquo;burogu\u0026rdquo; in Japanese. Maybe 6 (ro) and 9 (gu). So 6-9 could be \u0026ldquo;rogu,\u0026rdquo; part of \u0026ldquo;burogu.\u0026rdquo;\nAlternatively, the word \u0026ldquo;blog.\u0026rdquo; B is the 2nd letter, L is the 12th, O is the 15th, G is the 7th. 2-12-15-7. Doesn\u0026rsquo;t fit into 4 digits. Hmm.\nHmm, maybe I\u0026rsquo;m overcomplicating. Maybe the best approach is to find a number where the digits can be read as a word related to reading. For example, \u0026ldquo;yomu\u0026rdquo; is 4 (yo) + 6 (mu). So 4-6-XX. But need four digits. Maybe 4-6-1-9 (yo-mu-i-kyu). \u0026ldquo;Yomu iku\u0026rdquo; (to read and go). Not perfect, but maybe a stretch.\nAlternatively, 4-6-1-1 (yo-mu-i-i). \u0026ldquo;Yomu ii\u0026rdquo; (good to read). That could work! 4611. Let\u0026rsquo;s check: 4 (yo), 6 (mu), 1 (i), 1 (i). \u0026ldquo;Yomu ii\u0026rdquo; (読むいい) which means \u0026ldquo;good to read.\u0026rdquo; That\u0026rsquo;s a possible candidate. But 4611. Is that a valid port? Ports are 0-65535, so yes. And not reserved. So 4611 as \u0026ldquo;yomu ii\u0026rdquo; (good to read). That might be a good fit.\nYou can really see it examining different alternatives, but ultimately coming back to the best choice, in my opinion, with \u0026ldquo;4-6,\u0026rdquo; which reads \u0026ldquo;yo-mu\u0026rdquo; (to read). It thought a bit more after the \u0026ldquo;4-6-1-1\u0026rdquo; thought, but ultimately that was its answer. Which I\u0026rsquo;m quite happy with!\nAs a comparison, I asked the same prompt to ChatGPT 4.0 and got this:\nHere’s an idea for a goroawase port number related to reading, RSS, or blogs: 8645 (ハムシゴ, \u0026ldquo;Ha-mu-shi-go\u0026rdquo;) Breakdown: 8 = ハ (Ha) 6 = ム (Mu) 4 = シ (Shi) 5 = ゴ (Go) Interpretation: It loosely sounds like \u0026ldquo;読む仕事\u0026rdquo; (yomu shigoto), meaning \u0026ldquo;reading job\u0026rdquo; or \u0026ldquo;reading work,\u0026rdquo; which aligns nicely with the idea of an RSS reader for staying on top of blog content. Let me know if you\u0026rsquo;d like to brainstorm others!\nWhich is quite bad (it should be 4 instead of 8). OpenAI thought for 27 seconds and came up with:\n1106 → いい本 (ii hon) In Japanese, “いい” (ii) means “good” and “本” (hon) means “book.” So 1106 can be read as “ii hon,” literally “good book.” It’s quick to say, easy to remember, and ties nicely to the idea of reading!\nWhich was a bit better, but ultimately I went with Deepseek\u0026rsquo;s 4611 to host my RSS reader, Miniflux, on my Raspberry.\nThey are building an elevated highway not far from my place, so I get to see the progress daily. Currently, they are laying down the beams across the pillars. It\u0026rsquo;s quite impressive from my point of view (we don\u0026rsquo;t see a lot of those in France). It must require a lot of organization. Last week, I got stuck in a 10-person, 1-hour meeting to discuss a feature to allow for the import of a CSV into our app. At those times, I kind of wish I was doing some \u0026ldquo;real\u0026rdquo; work instead of this.\n","permalink":"https://blog.jmarhic.com/post/2025-01-27-happy-lunar-new-year/","summary":"\u003cp\u003eThis week it\u0026rsquo;s Lunar New Year, or Têt celebrations in Vietnam. Which means my daughter\u0026rsquo;s school is off, which means I get approximately 30 seconds of free time per day. Despite that, it was hard to miss the hype regarding the release of Deepseek R1. I didn\u0026rsquo;t have time to read the paper or anything, but I gave it a quick try at \u003ca href=\"chat.deepseek.com\"\u003echat.deepseek.com\u003c/a\u003e. I still don\u0026rsquo;t have a good handle on what is a good \u0026ldquo;reasoning question,\u0026rdquo; but I came up with a good use case today: coming up with a memorable port number for a service I\u0026rsquo;m hosting locally.\u003c/p\u003e","title":"Happy Lunar New Year"},{"content":"On the 7th of January, I received this surprising email from Google:\nHi Jerome,\nWe wanted to let you know about an upcoming software update for your Pixel 4a that will affect the overall performance and stability of its battery. Pixel phones, like other smartphones, use rechargeable lithium-ion batteries that, over time, may experience performance, capacity, or runtime degradation.\nIn the coming days, your Pixel 4a will receive an automatic software update to Android 13 that introduces new battery management features to improve the stability of the battery. This update will reduce your battery’s runtime and charging performance.\nTo address this, we’re providing some options to consider. Please take a look and choose which one works best for you.\nMore details related to this change are available here. Eligibility criteria and other terms will apply.\nThank you,\nPixel team\nLike\u0026hellip; okay, this update will reduce my battery\u0026rsquo;s runtime and charging performance, but it must be justified for some reason, right? Care to tell me?\nThe speculation online is that they reduced the battery capacity due to some issue with aging batteries\u0026hellip;\nAs promised, the update reduced the battery\u0026rsquo;s runtime a lot. I\u0026rsquo;m now charging twice a day, and it doesn\u0026rsquo;t last through the night. The \u0026ldquo;options to consider\u0026rdquo; were a choice of $50 cash or $100 toward a new Pixel phone on the Google Store. I\u0026rsquo;ve applied for the 50 bucks and increased my efforts to degoogle my life: I canceled my YouTube Premium subscription, and I\u0026rsquo;ll install Graphene OS on my Pixel 4a as soon as I get some free time.\nTo replace YouTube Premium, I\u0026rsquo;ve already set up a Tailscale \u0026ldquo;local network\u0026rdquo; between my devices, and I\u0026rsquo;m hosting a Jellyfin media server that I plan to fill up using yt-dlp. The process is pretty manual at the moment. Maybe it\u0026rsquo;s a use case for a future AI agent that could crawl YouTube daily and download some interesting recommendations for me.\nI\u0026rsquo;m still happy with Gmail, and Google Photos is stellar (especially compared to iCloud Photos, yuck), so I don\u0026rsquo;t plan on canceling my Google One storage plan any time soon. Speaking of storage, I\u0026rsquo;m hesitating between buying an external SSD to pair with my Raspberry Pi (keeping everything local, but with a big one-time expense) or using some online cloud storage as a networked drive. I already store some data at Backblaze for $6 per terabyte per month.\nOn another note, I\u0026rsquo;ve almost finished Baba Is You, but I\u0026rsquo;m stuck on a couple of remaining levels at the moment:\nWorld 4. Forest of Fall B \u0026ldquo;Broken Playground\u0026rdquo; World 5. Deep Forest E \u0026ldquo;Insulation\u0026rdquo; and 12 \u0026ldquo;Lock the Door\u0026rdquo; World 6. Rocket Trip 12 \u0026ldquo;Guardians\u0026rdquo; World 7. Bonus Level \u0026ldquo;Out at Sea\u0026rdquo; And there is some island on the bottom right of the overworld that I can\u0026rsquo;t reach at the moment (I have some idea, though, but I\u0026rsquo;m waiting to complete the above worlds first). Let\u0026rsquo;s try and make some progress on that next sprint, shall we? Can we estimate the difficulty? 3, 5, 8 points, XL, XS?\n","permalink":"https://blog.jmarhic.com/post/2025-01-22-rip-my-pixel-4a/","summary":"\u003cp\u003eOn the 7th of January, I received this surprising email from Google:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHi Jerome,\u003c/p\u003e\n\u003cp\u003eWe wanted to let you know about an upcoming software update for your Pixel 4a that will affect the overall performance and stability of its battery. Pixel phones, like other smartphones, use rechargeable lithium-ion batteries that, over time, may experience performance, capacity, or runtime degradation.\u003c/p\u003e\n\u003cp\u003eIn the coming days, your Pixel 4a will receive an automatic software update to Android 13 that introduces new battery management features to improve the stability of the battery. This update will reduce your battery’s runtime and charging performance.\u003c/p\u003e","title":"RIP my Pixel 4a"},{"content":"Already two weeks into January, it\u0026rsquo;s time for an update on my projects! I\u0026rsquo;m really happy with the progress on Prosettr.com, my crossword generation app. It will soon be time to share it with the world (HackerNews\u0026hellip;). Yesterday evening, I added login functionality (a choice of email + password or Google sign-in) using Firebase Authentication, as well as a button to load PUZ files.\nThe latter was surprisingly easy to do: I gave ChatGPT o1-mini the PUZ format description and asked it for a loader/writer in Go with my expectations for the input/output, followed by an HTTP handler. Thirty minutes later, here we are with the \u0026ldquo;Upload PUZ File\u0026rdquo; in production!\nIt seems like for every feature I add, I get an idea for another one, so I started prioritizing and separating \u0026ldquo;must-have\u0026rdquo; and \u0026ldquo;nice-to-have\u0026rdquo; features. \u0026ldquo;Nice-to-have\u0026rdquo; features include everything related to \u0026ldquo;word scores\u0026rdquo; (the \u0026ldquo;quality\u0026rdquo; of a word) and prioritizing high-quality words in the search. It\u0026rsquo;s important, but getting users first seems more important. The same goes for multithreading—I wish the search was faster, but for now, there is no one waiting for the results, so\u0026hellip;\n\u0026ldquo;Must-have\u0026rdquo; features, however, include finding a better word list, an export button, authenticating the backend endpoints, implementing per-user search quotas (easy now that users are logged in), writing an \u0026ldquo;About\u0026rdquo; page, etc. There\u0026rsquo;s so much left to do!\nI\u0026rsquo;m taking a week off at the end of the month for Lunar New Year. I\u0026rsquo;ll try to push and finish the app by then.\n","permalink":"https://blog.jmarhic.com/post/2025-01-14-january-2025-second-week-update/","summary":"\u003cp\u003eAlready two weeks into January, it\u0026rsquo;s time for an update on my projects! I\u0026rsquo;m really happy with the progress on \u003ca href=\"https://prosettr.com\"\u003eProsettr.com\u003c/a\u003e, my crossword generation app. It will soon be time to share it with the world (HackerNews\u0026hellip;). Yesterday evening, I added login functionality (a choice of email + password or Google sign-in) using Firebase Authentication, as well as a button to load PUZ files.\u003c/p\u003e\n\u003cp\u003eThe latter was surprisingly easy to do: I gave ChatGPT o1-mini the \u003ca href=\"https://gist.github.com/sliminality/dab21fa834eae0a70193c7cd69c356d5\"\u003ePUZ format description\u003c/a\u003e and asked it for a loader/writer in Go with my expectations for the input/output, followed by an HTTP handler. Thirty minutes later, here we are with the \u0026ldquo;Upload PUZ File\u0026rdquo; in production!\u003c/p\u003e","title":"January 2025, Second Week Update"},{"content":"2025 is off to a pretty good start! I spent 3 days alone in Phu Quoc to recharge, didn’t do anything except swimming and reading Thistlefoot while drinking coconuts. I used to go regularly when I was single, but now it\u0026rsquo;s going to be my last trip for a while. Got lucky with the weather as well!\nBack home, I’ve made some progress on my crossword solver app. I opened a WebSocket to stream the intermediary results (\u0026ldquo;dead ends\u0026rdquo;) as the backtracking algorithm progresses; I think it looks cool. In the frontend, I’ve added a history so you can Ctrl-Z, and other minor convenience changes (right-click to toggle between black and white cells, etc). I should define the scope, though; I don’t plan to make it a full-blown \u0026ldquo;crossword editor.\u0026rdquo; I think I will just add the ability to export a grid and be done with it.\nI hope to share it on Hacker News sometime this year. Reactions can be pretty harsh sometimes, but let’s see how this one goes.\nSpeaking of Hacker News, there was a funny blog post shared recently, \u0026ldquo;I am rich and have no idea what to do with my life\u0026rdquo;. The 1500+ reactions it generated were as expected (a mix of contempt and jealousy). Got some good links, though, especially this blog about \u0026ldquo;early retirement\u0026rdquo;. I’m generally happy, and I’ve got kids to take care of, so I feel like I’m in a good position to enjoy myself during early retirement—I just need to find the money!\n","permalink":"https://blog.jmarhic.com/post/2025-01-06-first-week-of-2025/","summary":"\u003ch3 id=\"2025-is-off-to-a-pretty-good-start\"\u003e2025 is off to a pretty good start!\u003c/h3\u003e\n\u003cp\u003eI spent 3 days alone in Phu Quoc to recharge, didn’t do anything except swimming and \u003ca href=\"https://www.goodreads.com/book/show/60018639-thistlefoot\"\u003ereading Thistlefoot\u003c/a\u003e while drinking coconuts. I used to go regularly when I was single, but now it\u0026rsquo;s going to be my last trip for a while. Got lucky with the weather as well!\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Phu Quoc picture\" loading=\"lazy\" src=\"/assets/images/onglang_beach_phu_quoc_2024.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eBack home, I’ve made some progress on my crossword solver app. I opened a WebSocket to stream the intermediary results (\u0026ldquo;dead ends\u0026rdquo;) as the backtracking algorithm progresses; I think it looks cool. In the frontend, I’ve added a history so you can Ctrl-Z, and other minor convenience changes (right-click to toggle between black and white cells, etc). I should define the scope, though; I don’t plan to make it a full-blown \u0026ldquo;crossword editor.\u0026rdquo; I think I will just add the ability to export a grid and be done with it.\u003c/p\u003e","title":"First week of 2025"},{"content":"Looking back, 2024 was a pretty good year across all metrics! Learned new things at work even though it\u0026rsquo;s my 5th year at the job, been pretty healthy and fit, not been drinking much (was a dry NYE, and will be doing a dry January). So I\u0026rsquo;m not taking any big resolutions for this year; it should be plenty busy already with the birth of my second kid in a few months. I\u0026rsquo;ll just try to finish and release my crossword generator application before that, and that will be it. Maybe try to be more smiley and relaxed in general.\nOver the holidays, I\u0026rsquo;ve made some progress on that crossword app. I\u0026rsquo;ve been mostly focused on reducing the memory footprint. The original implementation used more than 30GB for a 15x15 grid; I\u0026rsquo;ve managed to reduce it to about 5GB — first by using a sparse matrix, then by ditching the matrix altogether and generating rows one by one. I was wondering what the Go equivalent for Ruby\u0026rsquo;s \u0026ldquo;yield\u0026rdquo; would be. I wanted something like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 def generate_data (1..10).each do |i| yield i end end def process_data(data) puts data end generate_data do |data| process_data(data) end Go channels are really convenient for this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 dataChan := make(chan int) // could be buffered or not go func() { defer close(dataChan) for i := 0; i \u0026lt; 10; i++ { dataChan \u0026lt;- i } }() for i := range dataChan { println(i) } It\u0026rsquo;s clean, and actually even better because the next data point can be generated concurrently while the current one is being processed.\nAnother stretch goal of mine is to complete Baba is You. I\u0026rsquo;ve been at it for the past few months already, usually playing one or two levels before sleeping. It\u0026rsquo;s a nice feeling of achievement to see the \u0026ldquo;Congratulations\u0026rdquo; banner before going to bed, and as is often the case with brain stuff, if I get stuck at night, I can usually solve it the next day. With all the AGI talk and the recent ARC-AGI achievements by OpenAI\u0026rsquo;s O3 model, I\u0026rsquo;ve been thinking that I would personally consider AGI reached if a model could solve any random Baba is You level, with all the \u0026ldquo;thinking outside the box\u0026rdquo; required. I think the current \u0026ldquo;test-time compute\u0026rdquo; approach is appropriate here; it should be possible to have an LLM generate ideas and a verifier checking what the result of a given action is.\n","permalink":"https://blog.jmarhic.com/post/2025-01-02-and-a-happy-new-year-2025/","summary":"\u003cp\u003eLooking back, 2024 was a pretty good year across all metrics! Learned new things at work even though it\u0026rsquo;s my 5th year at the job, been pretty healthy and fit, not been drinking much (was a dry NYE, and will be doing a dry January). So I\u0026rsquo;m not taking any big resolutions for this year; it should be plenty busy already with the birth of my second kid in a few months. I\u0026rsquo;ll just try to finish and release my crossword generator application before that, and that will be it. Maybe try to be more smiley and relaxed in general.\u003c/p\u003e","title":"And a Happy New Year! (2025)"},{"content":"Since the release of ChatGPT more than 2 years ago, I have felt a strong disconnect with the opinions on HackerNews about AI. It really feels like an Anti-AI (especially anti-OpenAI) echo chamber, neverendingly predicting the advent of AI winters, always repeating the same arguments (usually some flavor of \u0026ldquo;it\u0026rsquo;s not intelligent\u0026rdquo;, \u0026ldquo;what is AGI?\u0026rdquo;, \u0026ldquo;how can you trust it?\u0026rdquo;). Well, given that the generated code compiles, the tests pass and the program works as expected, I\u0026rsquo;m not sure what there is to complain about. I feel that HN is about as wrong about AI as it was about cryptocurrencies. Eventually, I mostly stopped reading the comments, I just use it as a link aggregator now.\nSo I\u0026rsquo;m saying it proudly here instead, as a webdev ChatGPT and GitHub Copilot made me a good 50% more efficient. I think people that complain just don\u0026rsquo;t use it properly - learn to prompt ffs, it can\u0026rsquo;t read your mind. If you don\u0026rsquo;t know what you are doing and what result you even expect, you\u0026rsquo;re unlikely to get something satisfying.\nAnd from my experience, 0.1x programmers will never admit to their own failings. Whether it\u0026rsquo;s in online forums or in sprint retrospectives, the reason for failure is always external (those managers! the API!) and never their own inadequacies. So with AI, they will blame the tool for not working, instead of realizing they did not use it properly.\nI\u0026rsquo;ll concede however that some use cases are more suitable than others, personally I found I get better results with typed languages, notably in Go, since you can see at a glance whether the generated code is at least syntactically correct, and it helps the model plug into your existing program. Also, the current ChatGPT 4.0 version doesn\u0026rsquo;t seem to know much about Go 1.23 changes and will usually default to older Go constructions, but that\u0026rsquo;s my responsibility as a programmer to stay up-to-date about it and make sure I get the result I want. I\u0026rsquo;d say this is my value add now.\nSo these days, an usual development loop goes like this: I have a goal in mind (let\u0026rsquo;s say for instance, I don\u0026rsquo;t want the handler to take a filepath, but instead whatever the file content is). I\u0026rsquo;ll add the relevant code to the context with \u0026ldquo;Add File to Chat\u0026rdquo; - I can usually add the whole file as I try to not make them too long - and ask my question plainly and politely \u0026ldquo;please change the handler so it takes a list of strings from the file, instead of a filepath\u0026rdquo;. That\u0026rsquo;s normally enough to get going, and a cursory look at the changes is enough to validate that I got the result I expected. Oh nice it even updated the comments, LGTM! Another pass to update the tests, and I got a PR ready in 5 minutes instead of maybe 20 if I had done it by myself?\nDid I say \u0026ldquo;a list of strings\u0026rdquo;? I\u0026rsquo;ve been working on and off on this \u0026ldquo;crossword generator\u0026rdquo; project, and maybe it\u0026rsquo;s time to share a first preview: So what we have here is a Vue.js + TailwindCSS app (The frontend including the grid design was entirely generated by ChatGPT). And the \u0026ldquo;Solve Crossword\u0026rdquo; button calls the Go backend, which runs some backtracking algorithm - I wrote an \u0026ldquo;exact cover solver library\u0026rdquo; for that use - until it found a solution. It\u0026rsquo;s pretty fast, the search itself takes around 5 seconds if I start from an empty 15x15 grid (loading the word list every time is a bit slow though, so I\u0026rsquo;m going to ask Copilot to load it once and for all!). I have no plan to make the crossword solver open source though. I have some thoughts about open source that I might blog about later on!\nStill a lot of work to do (and not the funnest part unfortunately) before I can release it. First step would be to get a decent word list!\nAnyway, that\u0026rsquo;s it for the blog post. Even though I don\u0026rsquo;t use Copilot to generate the text, I\u0026rsquo;ll ask it to fix the typos :)\n","permalink":"https://blog.jmarhic.com/post/2024-12-25-how-i-use-github-copilot/","summary":"\u003cp\u003eSince the release of ChatGPT more than 2 years ago, I have felt a strong disconnect with the opinions on HackerNews about AI. It really feels like an Anti-AI (especially anti-OpenAI) echo chamber, neverendingly predicting the advent of AI winters, always repeating the same arguments (usually some flavor of \u0026ldquo;it\u0026rsquo;s not intelligent\u0026rdquo;, \u0026ldquo;what is AGI?\u0026rdquo;, \u0026ldquo;how can you trust it?\u0026rdquo;). Well, given that the generated code compiles, the tests pass and the program works as expected, I\u0026rsquo;m not sure what there is to complain about. I feel that HN is about as wrong about AI as it was about cryptocurrencies. Eventually, I mostly stopped reading the comments, I just use it as a link aggregator now.\u003c/p\u003e","title":"How I use GitHub Copilot"},{"content":"I took a day off on this Christmas day, and I got inspired to revive this blog by reading Simon Willison\u0026rsquo;s \u0026ldquo;approach to running a link blog\u0026rdquo;. I like his blog to keep updated about the new models\u0026rsquo; capabilities and developments in the AI world in general. He makes small experiments to put the models into practice, with a good dose of enthusiasm, and I want to follow a similar approach for this blog: sharing interesting articles I read, and some of my daily programming experiments, while \u0026ldquo;trying to add something extra\u0026rdquo;.\nIt\u0026rsquo;s one of my pet peeves at work; some colleagues will regularly share on Slack some article link, without any commentary on why they found it interesting or why it may be relevant or useful to our company. Just that random link (usually something that was already posted several days ago on HackerNews). That usually never triggers any discussion, at best a few thumbs-up emojis 👍. Not sure what their goal is, I assume it\u0026rsquo;s only to pretend they stay up to date technically. Thanks for nothing, I guess.\nAnyway, back to my blog. One first step I\u0026rsquo;m taking is to \u0026ldquo;Disable Completions for \u0026lsquo;Markdown\u0026rsquo;\u0026rdquo; in my code editor. I love it for code (more on that later), but even though I\u0026rsquo;m not a good writer, I want those words to be mine.\nOriginally I thought I would use this blog to \u0026ldquo;market myself\u0026rdquo; and my potential commercial projects, but I don\u0026rsquo;t actually have any at the moment, and it puts too much pressure on being \u0026ldquo;perfect\u0026rdquo; and I ended up sounding fake and not myself. My new reduced ambitions are just to post regular, imperfect blog posts (I might come back and edit them later on) about what I found interesting lately.\n","permalink":"https://blog.jmarhic.com/post/2024-12-25-merry-christmas/","summary":"\u003cp\u003eI took a day off on this Christmas day, and I got inspired to revive this blog by reading Simon Willison\u0026rsquo;s \u003ca href=\"https://simonwillison.net/2024/Dec/22/link-blog/\"\u003e\u0026ldquo;approach to running a link blog\u0026rdquo;\u003c/a\u003e. I like his blog to keep updated about the new models\u0026rsquo; capabilities and developments in the AI world in general. He makes small experiments to put the models into practice, with a good dose of enthusiasm, and I want to follow a similar approach for this blog: sharing interesting articles I read, and some of my daily programming experiments, while \u003ca href=\"https://simonwillison.net/2024/Dec/22/link-blog/#trying-to-add-something-extra\"\u003e\u0026ldquo;trying to add something extra\u0026rdquo;\u003c/a\u003e.\u003c/p\u003e","title":"Merry Christmas!"},{"content":"In this post, we\u0026rsquo;ll discuss various common ways of handling API rate limits, and I\u0026rsquo;ll introduce a new tool I\u0026rsquo;ve been working on called MeterFlow.\nMost APIs have rate limits, usually counted in requests per minute, but other resources can be limited as well (for instance, the number of characters you can translate with the Google Translate API, or the number of tokens you can generate with some LLM API). When you exceed the rate limit, the API will return a 429 status code, telling you to slow down. There are various ways of dealing with API rate limits in your code.\n1. Ignore it Some API rate limits are pretty high, and you might not need to worry about them too much if you know your usage is low. For instance, the Google Translate API has a 6 million characters, 300,000 requests per minute quota. If it is unlikely you are ever going to translate this much (at $20 per million characters, you would be spending $120 per minute!), you may have ignored the rate limit so far with no consequence.\n2. Sleep on it An easy method is to retry the request a couple of times, with some sleep time in between. Simple Ruby pseudo-code:\n1 2 3 4 5 6 7 8 9 10 11 12 retry_count = 0 begin response = make_request() rescue Faraday::ClientError =\u0026gt; e if e.response[:status] == 429 \u0026amp;\u0026amp; retry_count \u0026lt; MAX_RETRY_COUNT retry_count += 1 sleep 2 ** retry_count # exponential backoff retry else raise end end The request might succeed on the second or third try if the rate limit was reached temporarily due to a short burst of traffic. An alternative to sleeping is to raise an error and rely on Sidekiq\u0026rsquo;s retry mechanism to handle the retry.\nIn their cookbook, OpenAI suggests adding a delay proactively (sleeping before making the call), but it\u0026rsquo;s not ideal either (you are still paying for this CPU time!).\n3. Infrastructure rate limit If you are performing the API calls in the background (things like a Sidekiq job), you can limit the number of concurrent jobs (either with the number of processes/threads, or by making a capsule). For instance, if you are running 10 threads and each job takes at least 5 seconds to run, you know you won\u0026rsquo;t exceed 120 calls per minute to your external service.\n4. Introducing MeterFlow These solutions are not ideal: 1 and 2 can lead to failed requests, and 3 breaks anyway if you are calling the same API across multiple services (for instance, using an LLM endpoint to perform various tasks in separate microservices). Also, it is not easy to set a lower bound on your job execution time, so you\u0026rsquo;d have to account for some safety margin, leading to underutilization of your infrastructure. And anyway, you don\u0026rsquo;t want to run thousands of jobs and have them retry or sleep; ideally, you want to schedule them to run at the appropriate time.\nThis is where MeterFlow comes in. It is a simple, open-source service that can schedule your API calls, taking into account the current usage of the resource and the corresponding rate limits. The usage is simple: register a resource, then schedule calls to it. MeterFlow will return the delay before each call should be made.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Step 1: Request the schedule from MeterFlow uri = URI(\u0026#34;http://localhost:8080/schedule\u0026#34;) response = Net::HTTP.post( uri, { resource_name: \u0026#39;dummy_api\u0026#39;, num_calls: 1000 }.to_json, \u0026#34;Content-Type\u0026#34; =\u0026gt; \u0026#34;application/json\u0026#34; ) # Step 2: Parse the response and enqueue jobs based on the delay delays = JSON.parse(response.body)[\u0026#39;delays\u0026#39;] delays.each_with_index do |delay, index| DummyApiCallWorker.perform_in(delay, index + 1) end If all the API calls to a given resource across your organization are scheduled by MeterFlow, you can be sure you won\u0026rsquo;t exceed the rate limit. Planned features include support for multiple limits per resource (for instance, calls per minute + characters per hour, etc.) and Prometheus data export for monitoring.\n","permalink":"https://blog.jmarhic.com/post/2024-10-26-rate-limit/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll discuss various common ways of handling API rate limits, and I\u0026rsquo;ll introduce a new tool I\u0026rsquo;ve been working on called \u003ca href=\"https://github.com/goverture/meter_flow\"\u003eMeterFlow\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eMost APIs have rate limits, usually counted in requests per minute, but other resources can be limited as well (for instance, the number of characters you can translate with the Google Translate API, or the number of tokens you can generate with some LLM API). When you exceed the rate limit, the API will return a 429 status code, telling you to slow down. There are various ways of dealing with API rate limits in your code.\u003c/p\u003e","title":"Rate Limit"}]